[{"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Even for common NLP tasks, sufficient supervision is not available in many languages\u2014morphological tagging is no exception. In the work presented here, we explore a transfer learning scheme, whereby we train character-level recurrent neural taggers to predict morphological taggings for high-resource languages and low-resource languages together. Learning joint character representations among multiple related languages successfully enables knowledge transfer from the high-resource languages to the low-resource ones, improving accuracy by up to 30%.", "output": "Cross-lingual, Character-Level Neural Morphological Tagging", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Causality has been recently introduced in databases, to model, characterize and possibly compute causes for query results (answers). Connections between queryanswer causality, consistency-based diagnosis, database repairs (wrt. integrity constraint violations), abductive diagnosis and the view-update problem have been established. In this work we further investigate connections between query-answer causality and abductive diagnosis and the view-update problem. In this context, we also define and investigate the notion of query-answer causality in the presence of integrity constraints.", "output": "Causes for Query Answers from Databases, Datalog Abduction and View-Updates: The Presence of Integrity Constraints", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Named Entity Recognition (NER) models for language L are typically trained using annotated data in that language. We study cross-lingual NER, where a model for NER in L is trained on a source language (or multiple source languages). We introduce a language independent method for NER, building on cross-lingual wikification, a technique that grounds words and phrases in a non-English text into English Wikipedia entries. Thus, mentions in text in any language can be described using a set of categories and FreeBase types, yielding, as we show, strong languageindependent features. With this insight, we propose an NER model that can be applied to all languages in Wikipedia. When trained on English, our model outperforms comparable approaches on the standard CoNLL datasets (Spanish, German, and Dutch) and also performs very well on low-resource languages (Turkish, Tagalog, Yoruba, Bengali, and Tamil) that have significantly smaller Wikipedia. Moreover, our methods allows us to train on multiple source languages, typically improving NER results on the target languages. Finally, we show that our languageindependent features can be used also to enhance monolingual NER systems, yielding improved results for all 9 languages.", "output": "Cross-Lingual Named Entity Recognition via Wikification", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Detecting a small number of outliers from a set of data observations is always challenging. This problem is more difficult in the setting of multiple network samples, where computing the anomalous degree of a network sample is generally not sufficient. In fact, explaining why the network is exceptional, expressed in the form of subnetwork, is also equally important. In this paper, we develop a novel algorithm to address these two key problems. We treat each network sample as a potential outlier and identify subnetworks that mostly discriminate it from nearby regular samples. The algorithm is developed in the framework of network regression combined with the constraints on both network topology and L1-norm shrinkage to perform subnetwork discovery. Our method thus goes beyond subspace /subgraph discovery and we show that it converges to a global optimum. Evaluation on various real-world network datasets demonstrates that our algorithm not only outperforms baselines in both network and high dimensional setting, but also discovers highly relevant and interpretable local subnetworks, further enhancing our understanding of anomalous networks.", "output": "Outlier Detection from Network Data with Subnetwork Interpretation", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Understanding physical phenomena is a key competence that enables humans and animals to act and interact under uncertain perception in previously unseen environments containing novel object and their configurations. Developmental psychology has shown that such skills are acquired by infants from observations at a very early stage. In this paper, we contrast a more traditional approach of taking a modelbased route with explicit 3D representations and physical simulation by an end-to-end approach that directly predicts stability and related quantities from appearance. We ask the question if and to what extent and quality such a skill can directly be acquired in a data-driven way\u2014 bypassing the need for an explicit simulation. We present a learning-based approach based on simulated data that predicts stability of towers comprised of wooden blocks under different conditions and quantities related to the potential fall of the towers. The evaluation is carried out on synthetic data and compared to human judgments on the same stimuli.", "output": "To Fall Or Not To Fall: A Visual Approach to Physical Stability Prediction", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "We present a position paper advocating the notion that Stoic philosophy and ethics can inform the development of ethical A.I. systems. This is in sharp contrast to most work on building ethical A.I., which has focused on Utilitarian or Deontological ethical theories. We relate ethical A.I. to several core Stoic notions, including the dichotomy of control, the four cardinal virtues, the ideal Sage, Stoic practices, and Stoic perspectives on emotion or affect. More generally, we put forward an ethical view of A.I. that focuses more on internal states of the artificial agent rather than on external actions of the agent. We provide examples relating to near-term A.I. systems as well as hypothetical superintelligent", "output": "Stoic Ethics for Artificial Agents", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Machine learning relies on the assumption that unseen test instances of a classification problem follow the same distribution as observed training data. However, this principle can break down when machine learning is used to make important decisions about the welfare (employment, education, health) of strategic individuals. Knowing information about the classifier, such individuals may manipulate their attributes in order to obtain a better classification outcome. As a result of this behavior\u2014often referred to as gaming\u2014the performance of the classifier may deteriorate sharply. Indeed, gaming is a well-known obstacle for using machine learning methods in practice; in financial policy-making, the problem is widely known as Goodhart\u2019s law. In this paper, we formalize the problem, and pursue algorithms for learning classifiers that are robust to gaming. We model classification as a sequential game between a player named \u201cJury\u201d and a player named \u201cContestant.\u201d Jury designs a classifier, and Contestant receives an input to the classifier drawn from a distribution. Before being classified, Contestant may change his input based on Jury\u2019s classifier. However, Contestant incurs a cost for these changes according to a cost function. Jury\u2019s goal is to achieve high classification accuracy with respect to Contestant\u2019s original input and some underlying target classification function, assuming Contestant plays best response. Contestant\u2019s goal is to achieve a favorable classification outcome while taking into account the cost of achieving it. For a natural class of separable cost functions, and certain generalizations, we obtain computationally efficient learning algorithms which are near optimal, achieving a classification error that is arbitrarily close to the theoretical minimum. Surprisingly, our algorithms are efficient even on concept classes that are computationally hard to learn. For general cost functions, designing an approximately optimal strategy-proof classifier, for inverse-polynomial approximation, is NP-hard. ar X iv :1 50 6. 06 98 0v 1 [ cs .L G ] 2 3 Ju n 20 15", "output": "Strategic Classification", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "During the last years, Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in image classification. Their architectures have largely drawn inspiration by models of the primate visual system. However, while recent research results of neuroscience prove the existence of non-linear operations in the response of complex visual cells, little effort has been devoted to extend the convolution technique to non-linear forms. Typical convolutional layers are linear systems, hence their expressiveness is limited. To overcome this, various non-linearities have been used as activation functions inside CNNs, while also many pooling strategies have been applied. We address the issue of developing a convolution method in the context of a computational model of the visual cortex, exploring quadratic forms through the Volterra kernels. Such forms, constituting a more rich function space, are used as approximations of the response profile of visual cells. Our proposed second-order convolution is tested on CIFAR-10 and CIFAR-100. We show that a network which combines linear and non-linear filters in its convolutional layers, can outperform networks that use standard linear filters with the same architecture, yielding results competitive with the state-of-the-art on these datasets.", "output": "Non-linear Convolution Filters for CNN-based Learning", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "The payload of communications satellites must go through a series of tests to assert their ability to survive in space. Each test involves some equipment of the payload to be active, which has an impact on the temperature of the payload. Sequencing these tests in a way that ensures the thermal stability of the payload and minimizes the overall duration of the test campaign is a very important objective for satellite manufacturers. The problem can be decomposed in two sub-problems corresponding to two objectives: First, the number of distinct configurations necessary to run the tests must be minimized. This can be modeled as packing the tests into configurations, and we introduce a set of implied constraints to improve the lower bound of the model. Second, tests must be sequenced so that the number of times an equipment unit has to be switched on or off is minimized. We model this aspect using the constraint Switch, where a buffer with limited capacity represents the currently active equipment units, and we introduce an improvement of the propagation algorithm for this constraint. We then introduce a search strategy in which we sequentially solve the sub-problems (packing and sequencing). Experiments conducted on real and random instances show the respective interest of our contributions.", "output": "Constraint Programming for Planning Test Campaigns of Communications Satellites", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Learning features from massive unlabelled data is a vast prevalent topic for highlevel tasks in many machine learning applications. The recent great improvements on benchmark data sets achieved by increasingly complex unsupervised learning methods and deep learning models with lots of parameters usually requires many tedious tricks and much expertise to tune. However, filters learned by these complex architectures are quite similar to standard hand-crafted features visually. In this paper, unsupervised learning methods, such as PCA or auto-encoder, are employed as the building block to learn filter banks at each layer. The lower layer responses are transferred to the last layer (trans-layer) to form a more complete representation retaining more information. In addition, some beneficial methods such as local contrast normalization and whitening are added to the proposed deep trans-layer networks to further boost performance. The trans-layer representations are followed by block histograms with binary encoder schema to learn translation and rotation invariant representations, which are utilized to do high-level tasks such as recognition and classification. Compared to traditional deep learning methods, the implemented feature learning method has much less parameters and is validated in several typical experiments, such as digit recognition on MNIST and MNIST variations, object recognition on Caltech 101 dataset, face verification on LFW dataset. The deep trans-layer unsupervised learning achieves 99.45 % accuracy on MNIST dataset, 67.11 % accuracy on 15 samples per class and 75.98 % accuracy on 30 samples per class on Caltech 101 dataset, 87.10 % on LFW dataset.", "output": "Deep Trans-layer Unsupervised Networks for Representation Learning", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "<lb>We show that any model trained by a stochastic gradient method with few iterations has<lb>vanishing generalization error. We prove this by showing the method is algorithmically stable<lb>in the sense of Bousquet and Elisseeff. Our analysis only employs elementary tools from convex<lb>and continuous optimization. Our results apply to both convex and non-convex optimization<lb>under standard Lipschitz and smoothness assumptions.<lb>Applying our results to the convex case, we provide new explanations for why multiple<lb>epochs of stochastic gradient descent generalize well in practice. In the nonconvex case, we<lb>provide a new interpretation of common practices in neural networks, and provide a formal<lb>rationale for stability-promoting mechanisms in training large, deep models. Conceptually, our<lb>findings underscore the importance of reducing training time beyond its obvious benefit.", "output": "Stability of stochastic gradient descent", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "This article describes a software module called Akshara to Prosodeme (A2P) converter in Hindi. It converts an input grapheme into prosedeme (sequence of phonemes with the specification of syllable boundaries and prosodic labels). The software is based on two proposed finite state machines\u2014one for the syllabification and another for the syllable labeling. In addition to that, it also uses a set of nonlinear phonological rules proposed for foot formation in Hindi, which encompass solutions to schwa-deletion in simple, compound, derived and inflected words. The nonlinear phonological rules are based on metrical phonology with the provision of recursive foot structure. A software module is implemented in Python. The testing of the software for syllabification, syllable labeling, schwa deletion and prosodic labeling yield an accuracy of more than 99% on a lexicon of size 28664 words.", "output": "A Finite State and Rule-based Akshara to Prosodeme (A2P) Converter in Hindi", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Passengers\u2019 experience is becoming a key metric to evaluate the air transportation system\u2019s performance. Efficient and robust tools to handle airport operations are needed along with a better understanding of passengers\u2019 interests and concerns. Among various airport operations, this paper studies airport gate scheduling for improved passengers\u2019 experience. Three objectives accounting for passengers, aircraft, and operation are presented. Trade-offs between these objectives are analyzed, and a balancing objective function is proposed. The results show that the balanced objective can improve the efficiency of traffic flow in passenger terminals and on ramps, as well as the robustness of gate operations.", "output": "Airport Gate Scheduling for Passengers, Aircraft, and Operation", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "In this paper, we study the use of recurrent neural networks (RNNs) for modeling and forecasting time series. We first illustrate the fact that standard sequence-to-sequence RNNs neither capture well periods in time series nor handle well missing values, even though many real life times series are periodic and contain missing values. We then propose an extended attention mechanism that can be deployed on top of any RNN and that is designed to capture periods and make the RNN more robust to missing values. We show the effectiveness of this novel model through extensive experiments with multiple univariate and multivariate datasets.", "output": "Time Series Forecasting using RNNs: an Extended Attention Mechanism to Model Periods and Handle Missing Values", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Event factuality identification plays an important role in deep NLP applications. In this paper, we propose a deep learning framework for this task which first extracts essential information from raw texts as the inputs and then identifies the factuality of events via a deep neural network with a proper combination of Bidirectional Long Short-Term Memory (BiLSTM) neural network and Convolutional Neural Network (CNN). The experimental results on FactBank show that our framework significantly outperforms several state-of-the-art baselines.", "output": "Event Factuality Identification via Deep Neural Networks", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Probabilistic linear discriminant analysis (PLDA) is a popular normalization approach for the i-vector model, and has delivered state-of-the-art performance in speaker recognition. A potential problem of the PLDA model, however, is that it essentially assumes Gaussian distributions over speaker vectors, which is not always true in practice. Additionally, the objective function is not directly related to the goal of the task, e.g., discriminating true speakers and imposters. In this paper, we propose a max-margin metric learning approach to solve the problems. It learns a linear transform with a criterion that the margin between target and imposter trials are maximized. Experiments conducted on the SRE08 core test show that compared to PLDA, the new approach can obtain comparable or even better performance, though the scoring is simply a cosine computation.", "output": "Max-Margin Metric Learning for Speaker Recognition", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "We consider apprenticeship learning \u2014 i.e., having an agent learn a task by observing an expert demonstrating the task \u2014 in a partially observable environment when the model of the environment is uncertain. This setting is useful in applications where the explicit modeling of the environment is difficult, such as a dialogue system. We show that we can extract information about the environment model by inferring action selection process behind the demonstration, under the assumption that the expert is choosing optimal actions based on knowledge of the true model of the target environment. Proposed algorithms can achieve more accurate estimates of POMDP parameters and better policies from a short demonstration, compared to methods that learns only from the reaction from the environment.", "output": "Apprenticeship Learning for Model Parameters of  Partially Observable Environments", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "A totally semantic measure is presented which is able to calculate a similarity value between concept descriptions and also between concept description and individual or between individuals expressed in an expressive description logic. It is applicable on symbolic descriptions although it uses a numeric approach for the calculus. Considering that Description Logics stand as the theoretic framework for the ontological knowledge representation and reasoning, the proposed measure can be effectively used for agglomerative and divisional clustering task applied to the semantic web domain.", "output": "A Semantic Similarity Measure for Expressive Description Logics", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Embedding words in a vector space has gained a lot of research attention in re-<lb>cent years. While state-of-the-art methods provide efficient computation of word<lb>similarities via a low-dimensional matrix embedding, their motivation is often left<lb>unclear. In this paper, we argue that word embedding can be naturally viewed<lb>as a ranking problem. Then, based on this insight, we propose a novel frame-<lb>work WordRank that efficiently estimates word representations via robust ranking.<lb>The performance of WordRank is measured in word similarity and word analogy<lb>benchmarks, and the results are compared to the state-of-the-art word embedding<lb>techniques. Our algorithm produces a vector space with meaningful substructure,<lb>as evidenced by its performance of 77.4% accuracy on a popular word similarity<lb>benchmark and 76% on the Google word analogy benchmark. WordRank per-<lb>forms especially well on small corpora.", "output": "WordRank: Learning Word Embeddings via Robust Ranking", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Modeling spike firing assumes that spiking statistics is Poisson, but real data violates this assumption. To capture non-Poissonian features, in order to fix the inevitable inherent irregularity, researchers rescale the time axis with tedious computational overhead instead of searching for another distribution! Spikes or action potentials are precisely-timed changes in the ionic transport through synapses adjusting the synaptic weight, successfully modeled and developed as a memristor. Memristance value is multiples of initial resistance. This reminds us with the foundations of quantum mechanics. We try to quantize potential and resistance, as done with energy. After reviewing Planck curve for blackbody radiation, we propose the quantization equations. We introduce and prove a theorem that quantizes the resistance. Then we define the tyke showing its basic characteristics. Finally we give the basic transformations to model spiking and link an energy quantum to a tyke. Investigation shows how this perfectly models the neuron spiking., with over 97% match. All MATLA codes used are supplemented in the appendix.", "output": "Spike and Tyke, the Quantized Neuron Model", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "We present a character-level recurrent neural network that generates relevant and coherent text given auxiliary information such as a sentiment or topic. Using a simple input replication strategy, we preserve the signal of auxiliary input across wider sequence intervals than can feasibly be trained by back-propagation through time. Our main results center on a large corpus of 1.5 million beer reviews from BeerAdvocate. In generative mode, our network produces reviews on command, tailored to a star rating or item category. The generative model can also run in reverse, performing classification with surprising accuracy. Performance of the reverse model provides a straightforward way to determine what the generative model knows without relying too heavily on subjective analysis. Given a review, the model can accurately determine the corresponding rating and infer the beer\u2019s category (IPA, Stout, etc.). We exploit this capability, tracking perceived sentiment and class membership as each character in a review is processed. Quantitative and qualitative empirical evaluations demonstrate that the model captures meaning and learns nonlinear dynamics in text, such as the effect of negation on sentiment, despite possessing no a priori notion of words. Because the model operates at the character level, it handles misspellings, slang, and large vocabularies without any machinery explicitly dedicated to the purpose.", "output": "CHARACTER-LEVEL GENERATIVE TEXT MODELS", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Speech analysis had been taken to a new level with the discovery of Reverse Speech (RS). RS is the discovery of hidden messages, referred as reversals, in normal speech. Works are in progress for exploiting the relevance of RS in different real world applications such as investigation, medical field etc. In this paper we represent an innovative method for preparing a reliable Software Requirement Specification (SRS) document with the help of reverse speech. As SRS act as the backbone for the successful completion of any project, a reliable method is needed to overcome the inconsistencies. Using RS such a reliable method for SRS documentation was developed. Keywords\u2014 Reverse Speech, Software Requirement Specification (SRS), Speech Enhancement, Speech Recognition.", "output": "Software Requirement Specification Using Reverse Speech Technology", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "This paper presents an approach to formalizing and enforcing a class of use privacy properties in data-driven systems. In contrast to prior work, we focus on use restrictions on proxies (i.e. strong predictors) of protected information types. Our definition relates proxy use to intermediate computations that occur in a program, and identify two essential properties that characterize this behavior: 1) its result is strongly associated with the protected information type in question, and 2) it is likely to causally affect the final output of the program. For a specific instantiation of this definition, we present a program analysis technique that detects instances of proxy use in a model, and provides a witness that identifies which parts of the corresponding program exhibit the behavior. Recognizing that not all instances of proxy use of a protected information type are inappropriate, we make use of a normative judgment oracle that makes this inappropriateness determination for a given witness. Our repair algorithm uses the witness of an inappropriate proxy use to transform the model into one that provably does not exhibit proxy use, while avoiding changes that unduly affect classification accuracy. Using a corpus of social datasets, our evaluation shows that these algorithms are able to detect proxy use instances that would be difficult to find using existing techniques, and subsequently remove them while maintaining acceptable classification performance.", "output": "Use Privacy in Data-Driven Systems", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "We present a dictionary-based approach to racism detection in Dutch social media comments, which were retrieved from two public Belgian social media sites likely to attract racist reactions. These comments were labeled as racist or non-racist by multiple annotators. For our approach, three discourse dictionaries were created: first, we created a dictionary by retrieving possibly racist and more neutral terms from the training data, and then augmenting these with more general words to remove some bias. A second dictionary was created through automatic expansion using a word2vec model trained on a large corpus of general Dutch text. Finally, a third dictionary was created by manually filtering out incorrect expansions. We trained multiple Support Vector Machines, using the distribution of words over the different categories in the dictionaries as features. The best-performing model used the manually cleaned dictionary and obtained an F-score of 0.46 for the racist class on a test set consisting of unseen Dutch comments, retrieved from the same sites used for the training set. The automated expansion of the dictionary only slightly boosted the model\u2019s performance, and this increase in performance was not statistically significant. The fact that the coverage of the expanded dictionaries did increase indicates that the words that were automatically added did occur in the corpus, but were not able to meaningfully impact performance. The dictionaries, code, and the procedure for requesting the corpus are available at: https://github.com/clips/hades.", "output": "A Dictionary-based Approach to Racism Detection in Dutch Social Media", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "The success of kernel methods has initiated the design of novel positive semidefinite functions, in particular for structured data. A leading design paradigm for this is the convolution kernel, which decomposes structured objects into their parts and sums over all pairs of parts. Assignment kernels, in contrast, are obtained from an optimal bijection between parts, which can provide a more valid notion of similarity. In general however, optimal assignments yield indefinite functions, which complicates their use in kernel methods. We characterize a class of base kernels used to compare parts that guarantees positive semidefinite optimal assignment kernels. These base kernels give rise to hierarchies from which the optimal assignment kernels are computed in linear time by histogram intersection. We apply these results by developing the Weisfeiler-Lehman optimal assignment kernel for graphs. It provides high classification accuracy on widely-used benchmark data sets improving over the original Weisfeiler-Lehman kernel.", "output": "On Valid Optimal Assignment Kernels and Applications to Graph Classification", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "This work proposes a low complexity nonlinearity model and develops adaptive algorithms over it. The model is based on the decomposable\u2014or rank-one, in tensor language\u2014 Volterra kernels. It may also be described as a product of FIR filters, which explains its low-complexity. The rank-one model is also interesting because it comes from a well-posed problem in approximation theory. The paper uses such model in an estimation theory context to develop an exact gradienttype algorithm, from which adaptive algorithms such as the least mean squares (LMS) filter and its data-reuse version\u2014the TRUE-LMS\u2014are derived. Stability and convergence issues are addressed. The algorithms are then tested in simulations, which show its good performance when compared to other nonlinear processing algorithms in the literature.", "output": "Nonlinear Adaptive Algorithms on Rank-One Tensor Models", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "In this paper, we propose a framework for training multiple neural networks simultaneously. The parameters from all models are regularised by the tensor trace norm, so that one neural network is encouraged to reuse others\u2019 parameters if possible \u2013 this is the main motivation behind multi-task learning. In contrast to many deep multi-task learning work, we do not predefine a parameter sharing strategy by tying some (usually bottom) layers\u2019 parameters, instead, our framework allows the sharing for all shareable layers thus the sharing strategy is learned from a pure data-driven way.", "output": "Trace Norm Regularised Deep Multi-Task Learning", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Emotional content is a key element in user-generated videos. However, it is difficult to understand emotions conveyed in such videos due to the complex and unstructured nature of user-generated content and the sparsity of video frames that express emotion. In this paper, for the first time, we study the problem of transferring knowledge from heterogeneous external sources, including image and textual data, to facilitate three related tasks in video emotion understanding: emotion recognition, emotion attribution and emotion-oriented summarization. Specifically, our framework (1) learns a video encoding from an auxiliary emotional image dataset in order to improve supervised video emotion recognition, and (2) transfers knowledge from an auxiliary textual corpus for zero-shot recognition of emotion classes unseen during training. The proposed technique for knowledge transfer facilitates novel applications of emotion attribution and emotion-oriented summarization. A comprehensive set of experiments on multiple datasets demonstrate the effectiveness of our framework.", "output": "Heterogeneous Knowledge Transfer in Video Emotion Recognition, Attribution and Summarization", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "We study online boosting, the task of converting any weak online learner into a strong online learner. Based on a novel and natural definition of weak online learnability, we develop two online boosting algorithms. The first algorithm is an online version of boost-by-majority. By proving a matching lower bound, we show that this algorithm is essentially optimal in terms of the number of weak learners and the sample complexity needed to achieve a specified accuracy. This optimal algorithm is not adaptive, however. Using tools from online loss minimization, we derive an adaptive online boosting algorithm that is also parameter-free, but not optimal. Both algorithms work with base learners that can handle example importance weights directly, as well as by rejection sampling examples with probability defined by the booster. Results are complemented with an experimental study.", "output": "Optimal and Adaptive Algorithms for Online Boosting", "category": "Title Generation 636.json"}, {"instruction": "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words.", "input": "Although a number of related algorithms have been developed to evaluate influence diagrams, exploiting the conditional independence in the diagram, the exact solution has remained intractable for many important problems. In this paper we introduce decision circuits as a means to exploit the local structure usually found in decision problems and to improve the performance of influence diagram analysis. This work builds on the probabilistic inference algorithms using arithmetic circuits to represent Bayesian belief networks [Darwiche, 2003]. Once compiled, these arithmetic circuits efficiently evaluate probabilistic queries on the belief network, and methods have been developed to exploit both the global and local structure of the network. We show that decision circuits can be constructed in a similar fashion and promise similar benefits.", "output": "Evaluating influence diagrams with decision circuits", "category": "Title Generation 636.json"}]