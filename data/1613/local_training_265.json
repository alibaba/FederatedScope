[{"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @drunktweets81: You sure do have a pretty face for a cripple", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Bitches be having a nigga but want to be another nigga WCW bitch it don't work like that", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "The fucking store didn't have chessman cookies and I hate vanilla wafers so I had to improvise and use Lorna Doone cookies &#128580;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "You bitches got me all the way fucked up idc how many pineapples y'all eat your pussy still gon taste the same so give that shit up please", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Nd these hoes all kno I'm workin wit a 9 I ain't talking bout a gun I'm talking feel it in ya spine", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "on some field nigger shit", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "we are just worried about the wrong damn things as a society like who fucking cares if a woman wears makeup or weave. read a damn book", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @MsKeShera_: these bitches be sending shots but be missing me ian been @'d yet you cant be dissing me!", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"@_prettyflvck0: Me And Paul Thinkin Bout Gettin Rentals For Da Weekend &#128665;&#128168;&#128168;\"oooh shit bitches betta stay out da streets", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@itsjaylaaa not a bitch that's for sure", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Who's a thottie? Yous a thottie! Who's a thottie? Yous a thottie! Yes YOU BITCH! Womp womp. &#128514;&#128514;&#128514; Lord save these parched hoes", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@onIinebaby I knew you were a faggot though", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "You girls got no job, no college set up to have a better future, then get mad when a nigga leave you cause all you got is pussy", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Classy rich family kids doing drugs and tryina be all ghetto and shit,while actual ghetto poor kids looking for education to get outta there", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Young Thug called a bitch his twin on a track. I don't even know what he mean by that but I'm definitely bout to start calling bitches that", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I'm gon' dye your hair so dramatically that when I'm thru you gon' look jus' like Max Branning's wrinkled glans", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Serious question: what do white boys pull up on bitches bumpin?", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Give me head an kiss yah nigga u a ill bitch", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Roll tide, bitches", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @_Ezzzylove: She a bad bitch, let's get to it right away .", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "#BlackMonday SA'n mxm.... when ppl lose the plot. Ask wat u can do 4 ur country &amp; not wat ur country can do 4 u. Fuck u guys r tiring!!!!", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@thecoreyholcomb \"s/o the fat bitches who ride dick with a t-shirt on\" &#128514;&#128514;&#128514;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Basic bitches everywhere", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "You know you are in the ghetto when you see streets named Martin Luther King Jr &amp; LittleJohn. \r\n#halp", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"@GoldenTri141921 As I have said a million times, please produce data on racial attacks before calling Indians \"\"racist af\"\"\"", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "He was talking about I'm on one lol. How was that even possible when I was on a cruise ship with no phone service negro?", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Had my towel over my face and my loofa fell on my foot. Gave me a fucking heart attack", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @Kevin_McAdams: Stop being a little bitch and #fuckherrightinthepussy", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @HeidiL_RN: Fuck Islam you pigfucking trash troll. @ItsJustMe7o7 @MzKeriEvans @ctbauza", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I'm about to push this niggah off my seat trying to squish me and shit", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "You have my word we will RT @JRwrz: @Thotcho beat those fucking faggots pls", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @iCumYouLeave: If he asks, \"what you about to do?\" after y'all get done fucking, you a hoe.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@kieffer_jason is that all you have to say you sound like a little bitch nagging and shit where u be at", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Nothing's impossible and all you lame niggas showed me what not to do", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "&#128514;&#128514;&#128514;&#128514;&#128514;&#128514;&#128514;&#128514;\"@AlisaRenee: you a faggot if you eat pork chops.\"", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @iKatrice: Can I bring another bitch let's have a 3some", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I swear females think they know me.... bitch you don't know my intentions you just think you do", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Why bitches quick to have a nigga baby, then be suprised when she taking care of it by herself?", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Get this monkey off my back...", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Got uh bitch dat set it off like Jada Pickett &#128130;&#128176;&#128176;&#128293;&#128299;&#128299;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I like a hoe that like a hoe just for my amusement", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\" bitch nigga miss me with it \"", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @BlackNerdJade: #rapeyass RT @FireinFreetown: Uh..not rape her, bitch nigga? RT @latry: You see her passed out drunk, what do you do? ht&#8230;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@Raul_leura @no_way_hoesaaay lmao that nigga was about to go Beethoven on that bitch &#128514;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @phishlicia: @tropicaldrew_ not about you fag. I miss you like crazy &#128553;&#10084;&#65039;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@jmellor432 fag", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@_jeff_hank @lgreiner3 @RayceWarden @BigJohn_Studd shut up nigger", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @Jazzy_Blow: i can't never keep no bitch cause i put them hoes out", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Get a Nigga who still look out for you even when he mad &#128524;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "In 2015 I hooked up w this random tinder chick while my homies stole hella food from her fridge and that's why my 2016 sucked", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I like bad bitches cause they like bad bitches too", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "drop it a day early fuck niggas need to hear it now &#8220;@YoungGizzle_: #ED1 was so hard &#128293;but that's trash compared to #ED2&#8221;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Ok this is funny... A proud liberal who wants to end racism calls Tim Scott an Uncle Tom Lolz lib idiots #tcot http://t.co/y6X6eagw20", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Me and karima are checking out this cute boy at this gaming cafe omg. I suddenly love men!!! *deletes all tweets about how I hate men*", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"@BillTufts How do you define \"\"bailout\"\"? The key factor in plan soundness is interest rates, which are slowly moving up. Agree?\"", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "almost fucked up and screen shotted something on snapchat &#128514;&#128514;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @CashOutMolly: bitches is stupid .. they get cheated on BY THEY MAN and wanna go fight the girl . NO BITCH leave that nigga and move on &#8230;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "&#8220;@My_Fish_Died: You dammn Weed potheads are annoying af on Twitter&#8221; weed and pot are the same thing faggot", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "This bitch and her cankles", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@Kendracae \"bitches ain't shit but hoes with tricks\"", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @Kerb_215: 1,2,3,4 how many niggers are in my store I knowwwww your stealing &#128514;&#128514;&#128514;, that vine still be having me weak", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "yeah these valley faggots can go fuck themselves", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @NikoWavy: Some hoes look better without they Avi enlarged...", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@Oxy_Jon @conleyfanclub one charlotte store, but of course they are faggots", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "We're about a week away from Trump signing an Executive order that says: Release Live Bears in the Fucken Poor Parts of America", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "WOW, what a day so far!! Thanks to everyone who came to Bb so far today! We are looking forward to another busy supper!", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Week one of this weight loss competition. Had a slow start but managed to drop 5lbs in one week. Need to drop another 7 over next 2 weeks.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Paula Patton pussy got a nigga on stage on his knees talmbout he gotta get her back tonight", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I love bad bitches it my fucking hobby, and yeah they're on all fours like a fucking doggy..", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "if you have that lil pussy stomach pouch thingy, don't wear no tight clothes. shit is unattractive.&#128567;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I want my bitch to answer if my ex calling, with my dick in her mouth", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Fuck all that Some bitches so disrespectful they don't care. They will talk , fuck , ya boyfriend and still speak to the girlfriend.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Nigga gone have to get a room like a bitch", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Joes parties got hoes but it's always hot as hell", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Jesus Christ, they have fucking Humpty Dumpty in this", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"I can say \"\" all dese bitches bald \"\" somebody gone get offended at the \"\" bald \"\" part and not the B word &#129318;&#127997;\u200d\u2642\ufe0f\"", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Can I jut go ONE day without people having me fucked up, PLEASE!!! Maybe my birthday...", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Shower rod that hoe http://t.co/TdZXBl6Isf", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "( does anyone else look at crybaby and love him so much it breaks your heart to remember he is blind?)", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Last night a young popular liberal writer published mild criticism about Bernie Sanders, so I harassed him with threats and bigoted slurs.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I'm so upset. Freelance journalists, writers you really need to escape the comfort zone of lazy writing.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "BC politicians fight to implement frightening convictions against rapists and bastards who throw acid on women! Spare beef hypocrite morons", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Niggas talk more then bitches these days", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Still downtown with these bitches.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Yo bitch on my dick she come to my crib she get passed around no love", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I ont care cuz I got hoes. Dats rite I got plenty of em", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "my curious cat is dead, the magic 8 ball is dead, my notifs are dead, &amp; i've got nothing else to say, lmao", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "She wants fame, money, and irrelevant people's validity, masked with a shell of self-dignity, and wants such perks without its negativity.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Take a bitch to Soho for some froyo, tell her she gon blow it, Romo", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Yaaasss! RT @LoveMsLiz: When a hoe is talking about how they really don't be hoes..... &#128530; like girl, if you gotta explain it.. 9/10 a hoe.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Fuck around wit me n my niggas n we'll turn dis bitch inside out", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @TheBloodShow: Why all these hoes be wearin flowers around they head. I hope a bee Sting they ASS", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "You better watch your hoe she fuckin everybody", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "&#8220;@TrillOg_Malik: @vintage_monroe_ slut hoe&#8221;thot whore", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @bclaymoore: Dude does his girlfriend's mom, trashes her wedding. Mopes to folk rock. #explainafilmplotbadly", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Old hoes get mad when you don't show them the attention they want.", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Mix it up, bitches.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I'm glad you hoes ain't my momma", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "The funny thing is the daughter never got kicked out on her one night stand, I didn't have the courage to tell her, her mom an official hoe", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "i swear some of u niggas so fucking wack. exposing a woman on the tl because she takes an interest in u?? how fucking lame", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "No girls no hoes just me myself and I", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "1 baby Momma no bitch no wife like PAC u need a thug in ya life", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "These hoes aint yours", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "mental illnesses are thrown around so much that now, everyone thinks they have some sort of mental illness but they have no idea", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "3 things i cant stand while dealing with a bitch! \r\n\r\nA. HIT FEET\r\nB. STANK ASS BREATH\r\nC. SKANK ASS WAYS", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@lord_jonesss none of my business ? Nigga if you get that I'm living with you lol and I'm stealing one of them bitches and 100k &#128056;&#9749;&#65039;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "&#8220;@_honeysays: My phone charging backwards &#128533;&#8221; retarded", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "the mom acts like a bitch doe like ok ur losing ur memory but don't be a cunt to ur daughter", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @JoeCool_TVC: You can't be a hoe saying that another girls a hoe. Your both hoes, it cancels each other out.", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "My walmart tee's count as designer? RT @StonyXx: These niggas hoes in designer clothes &#128557;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "if u are communicating sexually in any type of manner w a guy that has a girl &amp; u go around bragging like it's cute u need to revaluate&#128078;&#127996;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I get taken for granted, when I've been nothing but real and honest with everyone. I can take shit for granted too.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "It's funny when u get a black female mad they start acting ghetto then a bitch", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "This just really sucks man. It's like you lose the loved ones that you never would expect to lose...", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "i wonder if you know that sometimes he thinks we're safe here ... well, that's just how it is, i suppose", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"@MargaretBates1 That she is! I still claim her for bisexuals everywhere, even if JW was an idiot with his \"\"gay now!\"\" bs.\"", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I hate that when I have assigned seats they sit me by the most annoying bitches in the whole class.", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "didn't know i was detrimental to shreveport art scene by taking up for an artist that got fucked over :)", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Lingard isn't Ronaldo,he's had awful games and pissed me off but moaning here like we just gave Djemba Djemba a 5 year deal? Come on.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "&#8220;@__nijel: This hoe Mimi said \"I hurt my hand\" &#128529;&#8221;&#128514;&#128514;&#128514; bitch her throat &#128514;&#128514;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Ppl need to see that our beliefs are worth fighting for, or they will CONTINUE to accept GOP framing &amp; worldview. We can't be passive!", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @obeyyreggie: stfu hoe RT &#8220;@tedddydgaf: \"I'm proud to be African American\" \r\n- Proud African American\r\n\r\n\"I'm proud to be white\" \r\n- Racist\r\n&#8230;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Charles was eatin trash ass Dominoes in that pic...you know he was still poor at the time lol", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Man bitches love Beyonce....no punch line", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "the hope was real. My review @TheChainsmokers album 7/10 just wish more of there EDM side was more present- But definetely the feels &#128149;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "this is probably why the lena/mon el scene will cause tension between kara &amp; because lena is a fucking alien ?", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "henny cups on all that ice bitch i'm froze up", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"Just overheard this punchable statement at the Chattanooga Film Fest: \"\"THE BABADOOK is a garbage movie for garbage people.\"\" Fuck off, pleb.\"", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @Ciara_LisaaRoss: cant no bitch make me mad over a nigga i already had", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@iLLEGALLYBadd my boy said this last night. I'll be in the gym Bc I refuse to be sloppy like these bad built bitches lol", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @iAmScottyBravo: I hate when old bitches&#128117; wear clothes these young hoes be wearing&#128135;&#128089;&#128096;, like stay yo ass&#9995;&#128530; in yo age group", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "My worse bitch looks better than your main bitch. Now that's bad right there lol", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@areuseriousrn @harmon_lauren it's okay I'll get bitches on this dick anyway but thanks for the tip", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Put the weights back on the rack bitch!! Smdh lol Dick Chaney's! http://t.co/pThwskJhdY", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "&#8220;@NoChillPaz: Mom : Dont call a girl a bitch. That's somebody's daughter,sister,niece...\r\nMe : And somebody's bitch too&#8221;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Don't trust a bitch who's nail polish is chipping off.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "praying for all those who don't have a home in this crazy ass Georgia weather", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "This fat bitch just said \"next time don't forget my potato chips\" &#128514;&#128514;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "It's crazy how niggas being accused of rape doesn't bother y'all", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Nigga fuck up. Ain't none of that shit Goin down with yo niggas RT @FrancoisKilljoy: You niggas think you feeling &#128056;, bitch? My niggas &#128058; you", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "should i start discourse with eileen and hope it makes them stop telling my friends im a pedophile cus i'm fucking not?", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "U think them nigs u with is with u?", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Sleeping\u200b on a mattress on the floor, giving my cat a final cuddle before the big day tomorrow &#128557;. #movingday", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @Yansii_: Black bitches be like \"boy i told you not to get my hair wet\" http://t.co/CSG4OoPgkY", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "All my young boys round me saying \"get money and fuck these hoes\"", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@heydenbunsyolo @jordan536633 @bird_lovin yea native and black proud then a bitch", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "And I can't be known for fucking wit a trash bitch.", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Say my fuccn name hoe!", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"nigga who never been shot at before talking bout \"\"it's survival of the fittest in these streets\"\" foh\"", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @_ImOVERSEAS: Hoes out here selling pussy for some new uggs! You disqualified", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "spoiled fucking bitches who get whatever they want need to step off and re-evaluate their lives", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@cuunthiaaa @Fvnxy he's the \"fuck her right in the pussy\" guy", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "the person that is trying to hack me deleted all my drafts :( I'm gonna make this account unhackable just see", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@Tylar____ @xxJaiLynn Tylar shut up bitch . I usta make you these", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "OUR DEMOCRATIC COLLEAGUES HAVE DONE SOMETHING UNPRECEDENTED IN THE HISTORY OF THE SENATED, MITCH MCCONNELL? FUCK YOU!!!", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Lmaoo I should've seen that coming RT @DatBoyRayT: @1AlaaZ fat bitches need love to Craig", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@TweetsAndFreaks I told u ugly niggas get bitches young I promise u!! Work ya magic lol", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Defiantly going to see that new planet of the apes tonight", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"RT @ArizonaTiana: I hate ugly bitches who play around and say \"\"eww\"\" the only ewww thing is YOU UGLY &#128514;\"", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Attacking Syrian Army who fights ISIS and other terrorists groups mean supporting terrorists &#128578; #Syria #syriahoax @realDonaldTrump", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@Steven_ratata bye youre a queer", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @_PimpC: \"@koniikonn: &#8220;@_Weezy_Wee: If you ask me, every bitch gay&#8221; not me I'm all sexual\" Wtf is all sexual? If you don't mind me asking", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Pussy gotta be trash RT @Adolfhibsta: Her love life is so sad lol RT @cqminaj: im so glad khloe k dumped french's ghetto ass", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Tired of these niggas turning females into stuck up bitches", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @Lady_BlahBlah: furrybah *in my PayPay voice* RT @80sbaby4life: The hoes are for EVERYBODY my nigga!", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Bad bitches from Oakland, she could beeee a model", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I fucking hate Courtney &amp; Bryce from 13 reasons why like she is deadass trying to justify a rapist Girl bye", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I mean. I guess I start using this again, since faggot Facebook blocked me for saying mean things to lady gaga", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@SamTrap84 in this world we don't spank the monkey the monkey spanks us.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Let the niccas feel on her booty.. lmaoRT @55OptimusPrime: take her to the hood were they do most good", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"I hate when niggas throw \"\"&#128141;&#128141;&#128141;&#128141;\"\" under my pics... I don't speak emoji, are u getting me a ring? Are u gon wife me? Tell me what is it? &#129318;&#127998;\u200d\u2640\ufe0f\"", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "People won't fucking care if you tell them about your half-brained, toxic thoughts on a KOREAN BOY GROUP", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "the girl you care about probably fucking somebody tonight so just go play some 2k and go to bed", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "&#8220;@BreadTruckkBri: These hoes gon come &amp;&amp; go, i feel it.&#8221;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Got my own place , pay my own bills &amp; rent &amp; 2 jobs. Tf am I worried about a next bitch for?", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Remember that fear is there to guide you, not cripple you.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"Eff it. Let's go after the cripple.\" http://t.co/kSaMx1JPfV", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "#IKLeaderOfNation 8. Imran is a true role model for \u201cmoderate Muslims\u201d. He does not shy from referring to Islamic principles and ideals", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "If you're not attractive .... bitch you ain't making my drinks...! TF you think this is.?", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Leap tall hoes in a single bound.", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Person: hi Me: but Robin! Why aren't we talking about Robin? He's so damn talented and Beautiful. His performance as Oswald is amazing, he-", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "How come I won't pray but find time for a bitch", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "prayers up to my Polish brother who is pretending to be hurt after he got his shit stuffed then crumpled to the floor in mock pain", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "This bitch in 7-11 wit hella face tats. She a female duddy &#128527;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@anniec0429 ugly white bitch", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "when you're stupid, you don't know it. life is so easy. have you ever seen a depressed retard? i envy that.", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Yall hoes got nothing better to do than to gossip and play telephone.", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @iamKatJohnson: RT @1inkkofrosess: It's bout that time were I feel like beening a hard working woman .....and a stripper hoe by night do&#8230;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I'm at that point where I can have the exact woman I want so I ain't losing no sleep over a chick who can't get over her dealings wit niggas", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Memorizing Eminem lyrics isn't a bad thing. Cause one day you'll be at a karaoke party then you'll step up and blow people's fucking minds.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I only respect bitches that respect theyself.# truu", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @TAXSTONE: Y'all bitches got to learn the difference between like and love", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @STROCORLEONE @ThoughtsOfRandy @Yummys_World all deze hoes got past demons in em... YOLO nigga lol + Hahahahaha", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Niggas be frontin for some pussy they ain't wit me!!", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": ".@realDonaldTrump Shouldn't have pissed off everyone w/talent in Hollywood. We could've come up with a better piece of theater than Syria.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "it's gotten to the point where I literally don't care and I'm gonna start punching bitches if they don't move in the hallway", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Why do adults seem shocked when you tell them you don't know where you see yourself in 5 years, I DONT FUCKING KNOW!!!!", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Nd y'all thought bitches knew how to accessorize http://t.co/f8yDxkaz", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Yesterday: 2-2, -0.05 units Let's have a big one today! NBA has been red hot &#128293; L3: 11-2, +14.36u L7: 17-8, +14.04u L14: 30-18, +19.63u", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Yall letting these hoes fuck you with the strap after you said no?", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "&#8220;@UnLike_Society: Good pussy be making a nigga have to regroup&#8221; pull out and get your thoughts together&#128514;&#128514;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Im from the 210 you already know bout to bust a flow on this bitch hoe names miguel is chillin with my nigga tono", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I'm so fucking hungry and I don't go on break til 6-7", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "niggas talk bout hoes, but the same hoes be in their beds at night ctfuu", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "People fully need to stop disrespecting Shia Muslims , why are some of you lots so concerned about what others believe in ? bloody hell", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Stop using the word \"redskin(s)\".", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "AND THERES FLASHBACKS!!!!!! to the friendship with the ex friend who was murdered and meeting gds parents and being w p and cap and ugh", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Would you rather be a monkey or a gorilla? &#8212; Neither, they're both hairy! But if I had to choose, a monkey. They... http://t.co/h2RQF5OqWb", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Tell them hoes come here , cause it look like they forgot bout me , but the fact that they aint seen me , that should say alot bout me", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "This Mexican bitch almost just hit me with her car and she sped over the speed bump JUST SO SHE COULD DO IT OMFG", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Grow up bitch", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "These hoes be flawgen i swear bruh, a nigga dont want yall", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Dumb ass fake bitches childish shit!!! Talk mad shit about each other and back to BEST FRIENDS? lmao", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @iTAT_uPAY: Every females worried about being played, &amp; every nigga worried she a hoe. So nothing but games will b played wit that minds&#8230;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Only niggah on my TL so getting off now", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@PussyBeezus_ whatever hoe", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Smoke good weed with bad bitch and give a good girl bad habits", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "We want Unbiased Court Proceedings in Asaram Bapu Ji's case #RemoveUnfairPOCSOlaw &amp; stop POCSO Misuse ASAP!", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "My account is used for biz advice. This time, my advice is simple - don't use @yourdailytasks! Refund policy is not fulfilled.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "#BREAKING | Woman molested in a bar in Kolkata's Park Street area; Woman groped, beaten up by 4 men; FIR filed, 4 accused still free", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"this is probably where the awkward tension comes from... \"\"hey lena let me introduce you to...\"\" \"\"KEEP THAT BITCH OUT OF MY SIGHT\"\"\"", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@FlightYung that's what I call a crash dummy hoe", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Neat but not as obnoxious as I remember getting a rec for psycho pass and then avoiding it cause art style is so fucking ugly.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "The emoji I use when I'm flirting wit bitches ---&gt; &#128520;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Lol at bitches thinking Kanye is the perfect man because he opened the car door for his wife.. You bitches don't know wtf y'all need..", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@Staydelusional I texted u fag", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "There was a fucking hair in my frosty from Wendy's. I'm DONE.", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "I am extremely sad to have to admit that some of the best 21st century Arabic rhymes have been written by Jihadis", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "&#8220;@leynachristina: I'm driving myself insane.&#8221;fag", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"@adriwadrri: No love for these fuck niggas\" hoes*", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"@ivery5000 @cosmicfirepeace @g_mccray @nuzzel More like \"\"witless\"\" or \"\"dimwitted\"\" Russian agent. Zero wits.\"", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "what a retard lol", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Female Tamarin monkeys mate w/ 3- 4 males so when she has the baby the men don't know who the dad is and ALL help. Slutty, but clever AF!", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @ItsNotHarold: I've noticed that it mostly be the bitches whose hair don't even reach their shoulders that talk the most shit", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Naomi Campbell, Rihanna, Miley Cyrus?...Crazy bitches lol", "output": "Yes", "category": "Toxic Language Detection 1236.json"}]