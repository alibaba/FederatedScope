[{"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "The paper presents an interesting incremental approach for exploring new convolutional network hierarchies in an incremental manner after a baseline network has reached a good recognition performance.  The experiments are presented for the CIFAR-100 and ImageNet benchmarks by morphing various ResNet models into better performing models with somewhat more computation.  Although the baselines are less strong than those presented in the literature, the paper claims significant error reduction for both ImageNet and CIFAR-100.  The main idea of the paper is to rewrite convolutions into multiple convolutions while expanding the number of filters. It is quite unexpected that this approach yields any improvements over the baseline model at all.  However, for some of the basic tenets of network morphing, experimental evidence is not given in the paper. Here are some fundamental questions raised by the paper: - How does the quality of morphed networks compares to those with the same topology trained from scratch? - How does the incremental training time after morphing relate to that of the network trained from scratch? - Where is the extra computational cost of the morphed networks come from? - Why is the quality of the baseline ResNet models lag behind those that are reported in the literature and github? (E.g. the github ResNet-101 model is supposed to have 6.1% top-5 recall vs 6.6 reported in the paper) More evidence for the first three points would be necessary to evaluate the validity of the claims of the paper.  The paper is written reasonably well and can be understood quite well, but the missing evidence and weaker baselines make it looks somewhat less convincing.  I would be inclined to revise up the score if a more experimental evidence were given for the main message of the paper (see the points above).", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper proposed the group sparse auto-encoder for feature extraction. The author then stack the group sparse auto-encoders on top of CNNs to extract better question sentence representation for QA tasks.   Pros:  - group-sparse auto-encoder seems new to me. - extensive experiments on QA tasks.   Cons: - The idea is somewhat incremental. - Writing need to be improved.  - Lack of ablation studies to show the effectiveness of the proposed approach.   Moreover, I am not convinced by the author's answer regarding the baseline. A separate training stages of CNN+SGL for comparison is fine. The purpose is to validate and analyze why the proposed SGA is preferred rather than group lasso, e.g. joint training could improve, or the proposed group-sparse regularization outperforms l_21 norm, etc. However, we can't see it from the current experiments.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "1) Summary  This paper investigates the usefulness of decoupling appearance and motion information for the problem of future frame prediction in natural videos. The method introduces a novel two-stream encoder-decoder architecture, MCNet, consisting of two separate encoders -- a convnet on single frames and a convnet+LSTM on sequences of temporal differences -- followed by combination layers (stacking + convolutions) and a deconvolutional network decoder leveraging also residual connections from the two encoders. The architecture is trained end-to-end using the objective and adversarial training strategy of Mathieu et al.  2) Contributions  + The architecture seems novel and is well motivated. It is also somewhat related to the two-stream networks of Simonyan & Zisserman, which are very effective for real-world action recognition. + The qualitative results are numerous, insightful, and very convincing (including quantitatively) on KTH & Weizmann, showing the benefits of decoupling content and motion for simple scenes with periodic motions, as well as the need for residual connections.  3) Suggestions for improvement  Static dataset bias: In response to the pre-review concerns about the observed static nature of the qualitative results, the authors added a simple baseline consisting in copying the pixels of the last observed frame. On the one hand, the updated experiments on KTH confirm the good results of the method in these conditions. On the other hand, the fact that this baseline is better than all other methods (not just the authors's) on UCF101 casts some doubts on whether reporting average statistics on UCF101 is insightful enough. Although the authors provide some qualitative analysis pertaining to the quantity of motion, further quantitative analysis seems necessary to validate the performance of this and other methods on future frame prediction. At least, the results on UCF101 should be disambiguated with respect to the type of scene, for instance by measuring the overall quantity of motion (e.g., l2 norm of time differences) and reporting PSNR and SSIM per quartile / decile. Ideally, other realistic datasets than UCF101 should be considered in complement. For instance, the Hollywood 2 dataset of Marszalek et al would be a good candidate, as it focuses on movies and often contains complex actor, camera, and background motions that would make the \"pixel-copying\" baseline very poor. Experiments on video datasets beyond actions, like the KITTI tracking benchmark, would also greatly improve the paper.  Additional recognition experiments: As mentioned in pre-review questions, further UCF-101 experiments on action recognition tasks by fine-tuning would also greatly improve the paper. Classifying videos indeed requires learning both appearance and motion features, and the two-stream encoder + combination layers of the MCNet+Res architecture seem particularly adapted, if they indeed allowed for unsupervised pre-trainining of content and motion representations, as postulated by the authors. These experiments would also contribute to dispelling the aforementioned concerns about the static nature of the learned representations.  4) Conclusion  Overall, this paper proposes an interesting architecture for an important problem, but requires additional experiments to substantiate the claims made by the authors. If the authors make the aforementioned additional experiments and the results are convincing, then this paper would be clearly relevant for ICLR.  5) Post-rebuttal final decision  The authors did a significant amount of additional work, following the suggestions made by the reviewers, and providing additional compelling experimental evidence. This makes this one of the most experimentally thorough ones for this problem. I, therefore, increase my rating, and suggest to accept this paper. Good job!", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper develops a differentiable interpreter for the Forth programming language. This enables writing a program \"sketch\" (a program with parts left out), with a hole to be filled in based upon learning from input-output examples. The main technical development is to start with an abstract machine for the Forth language, and then to make all of the operations differentiable. The technique for making operations differentiable is analogous to what is done in models like Neural Turing Machine and Stack RNN. Special syntax is developed for specifying holes, which gives the pattern about what data should be read when filling in the hole, which data should be written, and what the rough structure of the model that fills the hole should be. Motivation for why one should want to do this is that it enables composing program sketches with other differentiable models like standard neural networks, but the experiments focus on sorting and addition tasks with relatively small degrees of freedom for how to fill in the holes.  Experimentally, result show that sorting and addition can be learned given strong sketches.  The aim of this paper is very ambitious: convert a full programming language to be differentiable, and I admire this ambition. The idea is provocative and I think will inspire people in the ICLR community.  The main weakness is that the experiments are somewhat trivial and there are no baselines. I believe that simply enumerating possible values to fill in the holes would work better, and if that is possible, then it's not clear to me what is practically gained from this formulation. (The authors argue that the point is to compose differentiable Forth sketches with neural networks sitting below, but if the holes can be filled by brute force, then could the underlying neural network not be separately trained to maximize the probability assigned to any filling of the hole that produces the correct input-output behavior?)  Related, one thing that is missing, in my opinion, is a more nuanced outlook of where the authors believe this work is going. Based on the small scale of the experiments and from reading other related papers in the area, I sense that it is hard to scale up differentiable forth to large real-world problems. It would be nice to have more discussion about this, and perhaps even an experiment that demonstrates a failure case. Is there a problem that is somewhat more complex than the ones that appear in the paper where the approach does not work? What has been tried to make it work? What are the failure modes? What are the challenges that the authors believe need to be overcome to make this work.  Overall, I think this paper deserves consideration for being provocative. However, I'm hesitant to strongly recommend acceptance because the experiments are weak.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "A new sparse coding model is introduced that learns features jointly with their transformations. It is found that inference over per-image transformation variables is hard, so the authors suggest tying these variables across all data points, turning them into global parameters, and using multiple transformations for each feature. Furthermore, it is suggested to use a tree of transformations, where each path down the tree generates a feature by multiplying the root feature by the transformations associated with the edges. The one-layer tree model achieves similar reconstruction error as traditional sparse coding, while using fewer parameters.  This is a nice addition to the literature on sparse coding and the literature on learning transformation models. The authors identify and deal with a difficult inference problem that can occur in transformation models. That said, I am skeptical about the usefulness of the general approach. The authors take it as a given that \u201clearning sparse features and transformations jointly\u201d is an important goal in itself, but this is never really argued or demonstrated with experiments. It doesn\u2019t seem like this method enables new applications, extends our understanding of learning what/where pathways in the brain, or improve our ability to model natural images.  The authors claim that the model extracts pose information, but although the model explicitly captures the transformation that relates different features in a tree, at test time, inference is only performed over the (sparse) coefficient associated with each (feature, transformation) combination, just like in sparse coding. It is not clear what we gain by knowing that each coefficient is associated with a transformation, especially since there are many models that do this general \u201cwhat / where\u201d split.  It would be good to check that the x_{v->b} actually change significantly from their initialization values. The loss surface still looks pretty bad even for tied transformations, so they may actually not move much. Does the proposed model work better according to some measure, compared to a model where x_{v->b} are fixed and chosen from some reasonable range of parameter values (either randomly or spaced evenly)?  One of the conceptually interesting aspects of the paper is the idea of a tree of transformations, but the advantage of deeper trees is never demonstrated convincingly. It looks like the authors have only just gotten this approach to work on toy data with vertical and horizontal bars.  Finally, it is not clear how the method could be extended to have multiple layers. The transformation operators T can be defined in the first layer because they act on the input space, but the same cannot be done in the learned feature space. It is also not clear how the pose information should be further processed in a hierarchical manner, or how learning in a deep version should work.  In summary, I do not recommend this paper for publication, because it is not clear what problem is being solved, the method is only moderately novel and the novel aspects are not convincingly shown to be beneficial.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper delves into the mathematical properties of the skip-gram model, explaining the reason for its success on the analogy task and for the general superiority of additive composition models. It also establishes a link between skip-gram and Sufficient Dimensionality Reduction.  I liked the focus of this paper on explaining the properties of skip-gram, and generally found it inspiring to read. I very much appreciate the effort to understand the assumptions of the model, and the way it affects (or is affected by) the composition operations that it is used to perform. In that respect, I think it is a very worthwhile read for the community.  My main criticism is however that the paper is linguistically rather naive. The authors' use of 'compositionality' (as an operation that takes a set of words and returns another with the same meaning) is extremely strange. Two words can of course be composed and produce a vector that is a) far away from both; b) does not correspond to any other concept in the space; c) still has meaning (productivity wouldn't exist otherwise!) Compositionality in linguistic terms simply refers to the process of combining linguistic constituents to produce higher-level constructs. It does not assume any further constraint, apart from some vague (and debatable) notion of semantic transparency. The paper's implication (l254) that composition takes place over sets is also wrong: ordering matters hugely (e.g. 'sugar cane' is not 'cane sugar'). This is a well-known shortcoming of additive composition.   Another important aspect is that there are pragmatic factors that make humans prefer certain phrases to single words in particular contexts (and the opposite), naturally changing the underlying distribution of words in a large corpus. For instance, talking of a 'male royalty' rather than a 'king' or 'prince' usually has implications with regard to the intent of the speaker (here, perhaps highlighting a gender difference). This means that the equation in l258 (or for that matter the KL-divergence modification) does not hold, not because of noise in the data, but because of fundamental linguistic processes. This point may be addressed by the section on SDR, but I am not completely sure (see my comments below).  In a nutshell, I think the way that the authors present composition is flawed, but the paper convinces me that this is indeed what happens in skip-gram, and I think this is an interesting contribution.   The part about Sufficient Dimensionality Reduction seems a little disconnected from the previous argument as it stands. I'm afraid I wasn't able to fully follow the argument, and I would be grateful for some clarification in the authors' response. If I understand it well, the argument is that skip-gram produces a model where a word's neighbours follow some exponential parametrisation of a categorical distribution, but it is unclear whether this actually reflects the distribution of the corpus (as opposed to what happens in, say, a pure count-based model). The fact that skip-gram performs well despite not reflecting the data is that it implements some form of SDR, which does not need to make any assumption about the underlying form of the data. But then, is it fair to say that the resulting representations are optimised for tasks where geometrical regularities are important, regardless of the actual pattern of the data? I.e. there some kind of denoising going on?  Minor comments:  - The abstract is unusually long and could, I think, be shortened.  - para starting l71: I think it would be misconstrued to see circularity here. Firth observed that co-occurrence effects were correlated with similarity judgements, but those judgements are the very cognitive processes that we are trying to model with statistical methods. Co-occurrence effects and vector space word representations are in some sense 'the same thing', modelling an underlying linguistic process we do not have direct observations for. So pair-wise similarity is not there to break any circularity, it is there because it better models the kind of judgements humans known to make.  - l296: I think 'paraphrase' would be a better word than 'synonym' here, given that we are comparing a set of words with a unique lexical item.  - para starting l322: this is interesting, and actually, a lot of the zipfian distribution (the long tail) is fairly uniform.  - l336: it is probably worth pointing out that the analogy relation does not hold so well in practice and requires to 'ignore' the first returned neighbour of the analogy computation (which is usually one of the observed terms).  - para starting l343: I don't find it so intuitive to say that 'man' would be a synonym/paraphrase of anything involving 'woman'. The subtraction involved in the analogy computation is precisely not a straightforward composition operation, as it involves an implicit negation.   - A last, tiny general comment. It is usual to write p(w|c) to mean the probability of a word given a context, but in the paper 'w' is actually the context and 'c' the target word. It makes reading a little bit harder... Perhaps change the notation?  Literature:  The claim that Arora (2016) is the only work to try and understand vector composition is a bit strong. For instance, see the work by Paperno & Baroni on explaining the success of addition as a composition method over PMI-weighted vectors:  D. Paperno and M. Baroni. 2016. When the whole is less than the sum of its parts: How composition affects PMI values in distributional semantic vectors. Computational Linguistics 42(2): 345-350.  *** I thank the authors for their response and hope to see this paper accepted.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Comentarios generales: \u2022 Se habla de una plantilla, sin embargo en ninguna parte del art\u00edculo aparece esta plantilla \u2022 Se recomienda pueda ser incluida un ejemplo de recopilaci\u00f3n de datos en la plantilla \u2022 El agregar gr\u00e1ficos de datos analizados puede apoyar en una mejor comprensi\u00f3n del an\u00e1lisis que se realiz\u00f3. \u2022 Revisar todo el escrito ya que hay muchas inconsistencias en el escrito por ejemplo: art\u00edculos de m\u00e1s o faltan palabras \u2022 Revisar el espaciado de los p\u00e1rrafos \u2022 Se tiene muy poca bibliograf\u00eda \u2022 Revisar que las sangr\u00edas utilizadas como inicio de p\u00e1rrafo est\u00e9n acordes con el formato del congreso \u2022 Revisar el formato delas referencias bibliogr\u00e1ficas  Comentarios por secciones Palabras clave: \u2022 Revisar las palabras clave: \u2026caso de estudio, ISO 9126 Introducci\u00f3n \u2022 General\u2026.? \u2192 Generalmente o En general C. ISO 9126 \u2022 Se recomienda revisar la traducci\u00f3n realizada en la secci\u00f3n del ISO 9126, adem\u00e1s de tener cuidado en las sub caracter\u00edsticas que menciona y en lo que realmente luego describe ya que en m\u00e1s de una ocasi\u00f3n no coinciden los nombres. \u2022 La eficiencia no est\u00e1 descrita como lo viene haciendo con otros atributos de calidad \u2022 Revisar las sub caracter\u00edsticas incluidas en el atributo de portabilidad, en especial en las sub caracter\u00edsticas de efectividad, productividad, seguridad f\u00edsica y satisfacci\u00f3n, poner referencia de donde extrajo esa informaci\u00f3n Desarrollo de la plantilla \u2022 Entiendo que el primer bullet \u201cAl interactuar\u2026\u201d una breve descripci\u00f3n del momento en el que debes de contestar la pregunta asociada \u201c\u00bfExiste\u2026\u201d, recomiendo utilizar distintos bullets ya que as\u00ed como lo tienes causa confusi\u00f3n\u2026 as\u00ed en todos los apartados que aplique esta situaci\u00f3n Aplicaci\u00f3n del caso pr\u00e1ctico \u2022 Se recomienda una mejor descripci\u00f3n de los porcentajes por ejemplo agregar una tabla en la que se mencionen n\u00famero total de preguntas asociadas a cada atributo y el porcentaje asociado", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This nicely written paper presents an end-to-end learning method for image compression. By optimizing for rate-distortion performance and a clever relaxation the method is able to learn an efficient image compression method by optimizing over a database of natural images.  As the method is interesting, results are interesting and analysis is quite thorough it's easy for me to recommend acceptance.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Generales: - Recomiendo un cambio en el t\u00edtulo del art\u00edculo para que realmente refleje el contenido del mismo, ya que el t\u00edtulo es \"Costo Total de Propiedad para Servicios TI en la Industria Minera de la Segunda Regi\u00f3n de Chile.\" sin embargo, lo que haces es recopilar el estado del arte de costos, metodolog\u00edas, tipos de cat\u00e1logos de servicios y el alcance se queda en la definici\u00f3n de la metodolog\u00eda que se va a utilizar para formalizar  el TCO para servicios...entendi\u00e9ndose que est\u00e1n estableciendo las bases para algo que est\u00e1 en desarrollo, no que ya est\u00e9s mostrando el TCO desarrollado.  - ser coherente con el uso de referencias a lo largo de todos el art\u00edculo Resumen:  - Costo Total de Propiedad (TCO)-->(TCO, por sus siglas en ingl\u00e9s) - el art\u00edculo dar\u00e1 cuenta --> a que te refieres con se dar\u00e1 cuenta  Abtract: Revisar detalladamente la gram\u00e1tica y lo que se quiere expresar.  - which allows to identify, monitor and compare -->  allows identifying, monitoring and comparing - .. would be an important addition --> it would be an important addition - where categorical thematic analysis for the interviews that we will realize the cost management process will be performed will be performed; --> what???????? - will realize importance and relevance --> will realize the importance and the relevance -ending with the methodology --> Finally, we present the methodology...  Introducci\u00f3n: - Define las siglas AMSA  An\u00e1lisis Te\u00f3rico Gesti\u00f3n financiera - Figura 1 no se entiende, est\u00e1 muy peque\u00f1a hay que hacerla m\u00e1s grande y mejorar la calidad de la misma  Costos TI -gatos? -Categorizaci\u00f3n de costos --> hay que incluir las referencias de las fuentes de donde extrajo la informaci\u00f3n. - revisar falta de palabras como: d, cotos,...  Costo Total de Propiedad -Tabla aparece sin t\u00edtulo y fuera de lugar, esto es debe de aparecer despu\u00e9s del texto que hace referencia a ella, adem\u00e1s no estas manejando porcentajes en la tabla como lo mencionas \"dentro de los cuales se puede observar que el mayot porentaje de costo\" -revisar falta de palabras como:...con esta herramienta tener, mayaria  Metodolog\u00edas TCO -revisar falta de palabras como: buna las ilustraciones 5 y 10 no aparecen, adem\u00e1s si estan manejando el t\u00e9rmino \"figura\" estandariza en todos lados este t\u00e9rmino. - mejorar figura 2 (agrandar y mejorar calidad) y revisar la concordancia con el p\u00e1rrafo al que hace referencia a ella  Referencias: La referencia [8] no se encuentra", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "El art\u00edculo cumple con el requisito de presentar una experiencia empresarial en aplicaciones de TIC\u2019s con \u00e9nfasis en la miner\u00eda, por lo tanto, la evaluaci\u00f3n no se har\u00e1 teniendo en consideraci\u00f3n alguna propuesta innovativa en un art\u00edculo de car\u00e1cter cient\u00edfico.  Este art\u00edculo describe una experiencia exitosa en el uso de BPMN para modelar el proceso de negocio del \u00e1rea de Ingenier\u00eda y Proyectos de una empresa minera peruana. Se us\u00f3 un peque\u00f1o y simple conjunto de elementos de BPMN para modelar el proceso de negocio. Esta experiencia es v\u00e1lida, pero es una soluci\u00f3n ad hoc para el proceso de negocio escogido. La soluci\u00f3n tendr\u00eda mayor valoraci\u00f3n si se hubiese presentado un modelo peque\u00f1o que pudiese ser validado y que pudiese solucionar un conjunto determinado de procesos de negocio asociados a la miner\u00eda.  Algunas observaciones y/o comentarios menores: - No cumple con el requisito de presentar los art\u00edculos como an\u00f3nimos de autores e instituci\u00f3n. - En Resumen, cambiar \u201ccontrol sus procesos\u201d por \u201ccontrol de sus procesos\u201d. - En Introducci\u00f3n, cambiar \u201cbeneficios BPMNs\u201d por \u201cbeneficios de BPMN\u201d. - En p\u00e1gina 3 y otras, utiliza las palabras \u201cfigura\u201d y \u201cFigura\u201d en el texto. - En p\u00e1gina 5, cambiar \u201cLa figura 2 se ha incluido\u201d por \u201cEn la Figura 2 se han incluido\u201d. - La referencia a algunas figuras 3 y 4 (mostradas en p\u00e1gina 6) solamente se mencionan al final de la p\u00e1gina 7. Lo ideal es referenciarla primero y despu\u00e9s mostrar la figura. - En p\u00e1gina 7, cambiar \u201cel agrupa las tareas\u201d por \u201cagrupa las tareas\u201d. - En Referencia [5] cambiar \u201cBPMNModeling\u201d por \u201cBPMN Modeling\u201d. - La Referencia [7] debe ser completada, la Referencia [12] debe incluir el a\u00f1o.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Se presenta una aplicaci\u00f3n que consiste en un sistema de vigilancia basado en c\u00e1maras ip y que puede ser monitoreado desde dispositivos m\u00f3viles con android, donde el aporte del trabajo es crear un sistema centralizado para gestionar las c\u00e1maras. El paper muestra en detalle el dise\u00f1o del sistema, lo cual puede ser de inter\u00e9s a la audiencia del congreso. El trabajo presenta algunos problemas en el formato: - presenta encabezados en cada p\u00e1gina que parecen referenciar a que fue extra\u00eddo o enviado a una revista, lo cual no se adecua al formato del workshop -muestra tambi\u00e9n fechas de envi\u00f3 y recepci\u00f3n, lo cual parece apunta en la misma direcci\u00f3n - presenta algunos problemas de redacci\u00f3n y sentido, como: \"Tambi\u00e9n, a esto se suma la incomodidad el tener acceso de un computador\" \"presenta el desarrollo de un sistema de v\u00eddeo vigilancia con c\u00e1maras IP, que engloba las \u00bf\u00bfdesventajas?? antes nombradas\"  El paper deber\u00eda arreglar los problemas en el formato para ser aceptado", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Este art\u00edculo presenta los resultados de un experimento donde se evidencia que las t\u00e9cnicas de  co-creaci\u00f3n aplicadas a trav\u00e9s de las redes sociales y haciendo uso de dispositivos m\u00f3viles pueden potenciar la creatividad de los participantes. Es un tema interesante y que considero que puede ser aporte al congreso.  Se debe mejorar la forma de presentaci\u00f3n del art\u00edculo.  Algunas observaciones y/o comentarios: - Los dos primeros p\u00e1rrafos de la Introducci\u00f3n es casi la totalidad del Resumen. - En p\u00e1gina 4, cambiar \u201ccada que\u201d por \u201ccada vez\u201d. - En p\u00e1gina 5, Paso 3, no cierra par\u00e9ntesis en dos ocasiones. - Sugiero agrandar la Figura 2. - Considero excesivo utilizar una p\u00e1gina para una sola figura. - En la Referencia [11] , corregir \u201cConference on the, 2009\u201d - El n\u00famero de  p\u00e1gina 3 se repite tres veces. - Despu\u00e9s de la p\u00e1gina 7, sigue con la p\u00e1gina 3. - Referencia [4] dice \u201c2004b\u201d", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "The paper describes a method for training neural networks with ternary weights. The results are solid and have a potential for high impact on how networks for high-speed and/or low-power inference are trained.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper explores the use of Open Bigrams as a target representation of words, for application to handwriting image recognition.   Pros: - The use of OBs is novel and interesting. - Clearly written and explained.  Cons: - No comparison to previous state of the art, only with author-generated results.  - More ablation studies needed -- i.e. fill in Table3 with rnn0,1 rnn0,1,2 rnn0,1' etc etc. It is not clear where the performance is coming from, as it seems that it is single character modelling (0) and word endings (') that are actually beneficial. - While the use of Open bigrams is novel, there are works which use bag of bigrams and ngrams as models which are not really compared to or explored. E.g.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "El presente paper realiza una categorizaci\u00f3n de formas de integrar reglas de negocio en un dise\u00f1o utilizando el paradigma orientado a aspectos y propone una plantilla de documentaci\u00f3n para reglas de negocio basado en dicha categorizaci\u00f3n.  El paper entrega informaci\u00f3n \u00fatil sobre el problema en particular, as\u00ed como una categorizaci\u00f3n razonable de diferentes aspectos en este problema. Es un buen punto de partida para una investigaci\u00f3n en esa l\u00ednea.  Aunque la informaci\u00f3n entregada en el paper es de suma relevancia para una investigaci\u00f3n en este tema, es insuficiente para aceptarlo como un trabajo completo y autocontenido. La raz\u00f3n es que el paper se enfoca en identificar problemas y proponer un artefacto (la plantilla) que deber\u00eda resolver dichos problemas. Sin embargo no presenta evidencias de por qu\u00e9 esta plantilla es una buena alternativa para resolver dichos problemas. Para ello se requieren los elementos mencionados en el trabajo futuro, espec\u00edficamente la especificaci\u00f3n formal y la herramienta autom\u00e1tica para crear plantillas y mapearlas a AOP.  Mi sugerencia es esperar a que estos elementos est\u00e9n listos para completar este paper y enviarlo a una nueva conferencia.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Reviewers agree that the findings are not clear enough to be of interest, though the effort to do a controlled study is appreciated.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Se presenta la necesidad de usar Objetos de Aprendizaje (OA) para la ense\u00f1anza del curso \"Introducci\u00f3n a la Teor\u00eda de Aut\u00f3matas\". Sin embargo es muy poca la informaci\u00f3n dedicada en el art\u00edculo a los OA elegidos para el curso, no hay informaci\u00f3n de resultados de su aplicaci\u00f3n ni sus consecuencias (resultados de aprendizaje, encuesta a los alumnos para validarlo, etc.). Es por ello que no se recomienda aceptar el art\u00edculo, salvo que se agregue informaci\u00f3n que respalde la aplicaci\u00f3n de OA en este curso.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper tackles the problem of compressing trained convnets with the goal of reducing memory overhead and speeding up the forward pass. As I understand it, the main contribution of this work is to develop fast convolution routines for sparse conv weights int he case of general sparsity (as compared with structured sparsity). They evaluate their method on both AlexNet and GoogLeNet as well as on various platforms. The authors make code available online. The paper is well written and does a good job of putting this work in the context of past model reduction techniques.  My main request of the authors would be to provide a concise summary of the speedup/memory gains achievable with this new work compared with previously published work. The authors do show the various sparsity level obtained with various methods of pruning but it is unclear to me how to translate the information given in the paper into an understanding of gains relative to other methods.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper takes a model based on that of Graves and retrofits it with a representation derived from the work of Plamondon.  part of the goal of deep learning has been to avoid the use of hand-crafted features and have the network learn from raw feature representations, so this paper is somewhat against the grain.   The paper relies on some qualitative examples as demonstration of the system, and doesn't seem to provide a strong motivation for there being any progress here.  The paper does not provide true text-conditional handwriting synthesis as shown in Graves' original work.   Be more consistent about your bibliography (e.g. variants of Plamondon's own name, use of \"et al.\" in the bibliography etc.)", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "El trabajo, seg\u00fan los revisores, no presenta una contribuci\u00f3n cient\u00edfica directa en el \u00e1rea de rob\u00f3tica o sistemas difusos, sin embargo es una aplicaci\u00f3n muy interesante a ser presentada en el Workshop de Rob\u00f3tica de INFONOR 2013. Es por ello que se recomienda aceptar el art\u00edculo para su presentaci\u00f3n.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Novedosa propuesta, muy valorable la vinculaci\u00f3n de personas del \u00e1mbito empresarial lo que permite que la teor\u00eda y propuestas para ingenier\u00eda de software puedan ser probadas en ambientes reales. Bien estructurado y muy bien redactado.  Solo sugiero esquematizar las actividadesde aplicaci\u00f3n de entrenamiento White Belt IR - SixSigma y revisar peque\u00f1os detalles de redacci\u00f3n.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "- Strengths:  The paper is well-written and easy to understand. The methods and results are interesting.  - Weaknesses:  The evaluation and the obtained results might be problematic (see my comments below).  - General Discussion:  This paper proposes a system for end-to-end argumentation mining using neural networks. The authors model the problem using two approaches: (1) sequence labeling (2) dependency parsing. The paper also includes the results of experimenting with a multitask learning setting for the sequence labeling approach. The paper clearly explains the motivation behind the proposed model. Existing methods are based on ILP, manual feature engineering and manual design of ILP constraints. However, the proposed model avoids such manual effort. Moreover, the model jointly learns the subtasks in argumentation mining and therefore, avoids the error back propagation problem in pipeline methods. Except a few missing details (mentioned below), the methods are explained clearly.  The experiments are substantial, the comparisons are performed properly, and the results are interesting. My main concern about this paper is the small size of the dataset and the large capacity of the used (Bi)LSTM-based recurrent neural networks (BLC and BLCC). The dataset includes only around 320 essays for training and 80 essays for testing. The size of the development set, however, is not mentioned in the paper (and also the supplementary materials). This is worrying because very few number of essays are left for training, which is a crucial problem. The total number of tags in the training data is probably only a few thousand. Compare it to the standard sequence labeling tasks, where hundreds of thousands (sometimes millions) of tags are available. For this reason, I am not sure if the model parameters are trained properly. The paper also does not analyze the overfitting problem. It would be interesting to see the training and development \"loss\" values during training (after each parameter update or after each epoch). The authors have also provided some information that can be seen as the evidence for overfitting: Line 622 \"Our explanation is that taggers are simpler local models, and thus need less training data and are less prone to overfitting\".  For the same reason, I am not sure if the models are stable enough. Mean and standard deviation of multiple runs (different initializations of parameters) need to be included. Statistical significance tests would also provide more information about the stability of the models and the reliability of results. Without these tests, it is hard to say if the better results are because of the superiority of the proposed method or chance.  I understand that the neural networks used for modeling the tasks use their regularization techniques. However, since the size of the dataset is too small, the authors need to pay more attention to the regularization methods. The paper does not mention regularization at all and the supplementary material only mentions briefly about the regularization in LSTM-ER. This problem needs to be addressed properly in the paper.  Instead of the current hyper-parameter optimization method (described in supplementary materials) consider using Bayesian optimization methods.  Also move the information about pre-trained word embeddings and the error analysis from the supplementary material to the paper. The extra one page should be enough for this.  Please include some inter-annotator agreement scores. The paper describing the dataset has some relevant information. This information would provide some insight about the performance of the systems and the available room for improvement.  Please consider illustrating figure 1 with different colors to make the quality better for black and white prints.  Edit:  Thanks for answering my questions. I have increased the recommendation score to 4. Please do include the F1-score ranges in your paper and also report mean and variance of different settings. I am still concerned about the model stability. For example, the large variance of Kiperwasser setting needs to be analyzed properly. Even the F1 changes in the range [0.56, 0.61] is relatively large. Including these score ranges in your paper helps replicating your work.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Es un buen tema para el congreso. Presenta una buena propuesta de trabajo de vinculaci\u00f3n  Est\u00e1 redactado como un abstract extendido, debe ser re-escrito para ser aceptado definitivamente para el congreso. No hay referencias y las que coloca al final son pobres. Por la presentaci\u00f3n deber\u00eda ser castigado", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "- Strengths:  - Weaknesses: Many grammar errors, such as the abstract  - General Discussion:", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "El art\u00edculo presenta un sistema detecci\u00f3n y seguimiento de ojos para ayuda al an\u00e1lisis cl\u00ednico psicol\u00f3gico.  Comentarios generales.  En el tema que aborda el art\u00edculo se ha publicado bastante. Sin embargo, no se citan otros trabajos relevantes directamente relacionados, que nos ayuden a ubicar la propuesta dentro de la literatura. Un buen punto de inicio puede ser el n\u00famero especial de la revista: Computer Vision and Image Understanding Volume 98 ,  Issue 1  (April 2005) Special issue on eye detection and tracking  La parte experimental del trabajo es muy breve. Es importante describir detalladamente los datos empleados en la experimentaci\u00f3n, cu\u00e1les son las condiciones de captura, e incluso hacerlos p\u00fablicos para que otros investigadores puedan comparar con ellos. En cuanto a los resultados, no basta con dar un porcentaje de aciertos. Hay que analizar los falsos positivos y negativos y relacionarlos con la t\u00e9cnica utilizada y, si es posible, con los futuros temas a investigar.  Otros comentarios:  En el art\u00edculo se menciona que se ha considerado la velocidad de respuesta, pero no se proporcionan cifras.  En la introducci\u00f3n se cita la referencia [3] en la revisi\u00f3n relacionada sobre los aspectos psicol\u00f3gicos del art\u00edculo, cuando esta referencia parece ser de morfolog\u00eda matem\u00e1tica.  Algunas referencias est\u00e1n incompletas: + En la 1 y 2 falta la editorial + En la 3 la conferencia/revista. + En la 5 el volumen, n\u00famero y p\u00e1ginas  El art\u00edculo aborda un tema de gran inter\u00e9s t\u00e9cnico y pr\u00e1ctico.  Se describe un sistema que parece no estar completamente desarrollado.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "In light of the authors' responsiveness and the updates to the manuscript -- in particular to clarify the meta-learning task -- I am updating my score to an 8.  -----  This manuscript proposes to tackle few-shot learning with neural networks by leveraging meta-learning, a classic idea that has seen a renaissance in the last 12 months. The authors formulate few-shot learning as a sequential meta-learning problem: each \"example\" includes a sequence of batches of \"training\" pairs, followed by a final \"test\" batch. The inputs at each \"step\" include the outputs of a \"base learner\" (e.g., training loss and gradients), as well as the base learner's current state (parameters). The paper applies an LSTM to this meta-learning problem, using the inner memory cells in the *second* layer to directly model the updated parameters of the base learner. In doing this, they note similarities between the respective update rules of LSTM memory cells and gradient descent. Updates to the LSTM meta-learner are computed based on the base learner's prediction loss for the final \"test\" batch. The authors make several simplifying assumptions, such as sharing weights across all second layer cells (analogous to using the same learning rate for all parameters). The paper recreates the Mini-ImageNet data set proposed in Vinyals et al 2016, and shows that the meta-learner LSTM is competitive with the current state-of-the-art (Matchin Networks, Vinyals 2016) on 1- and 5-shot learning.  Strengths: - It is intriguing -- and in hindsight, natural -- to cast the few-shot learning problem as a sequential (meta-)learning problem. While the authors did not originate the general idea of persisting learning across a series of learning problems, I think it is fair to say that they have advanced the state of the art, though I cannot confidently assert its novelty as I am not deeply familiar with recent work on meta-learning. - The proposed approach is competitive with and outperforms Vinyals 2016 in 1-shot and 5-shot Mini-ImageNet experiments. - The base learner in this setting (simple ConvNet classifier) is quite different from the nearest-neighbor-on-top-of-learned-embedding approach used in Vinyals 2016. It is always exciting when state-of-the-art results can be reported using very different approaches, rather than incremental follow-up work. - As far as I know, the insight about the relationship between the memory cell and gradient descent updates is novel here. It is interesting regardless. - The paper offers several practical insights about how to design and train an LSTM meta-learner, which should make it easier for others to replicate this work and apply these ideas to new problems. These include proper initialization, weight sharing across coordinates, and the importance of normalizing/rescaling the loss, gradient, and parameter inputs. Some of the insights have been previously described (the importance of simulating test conditions during meta-training; assuming independence between meta-learner and base learner parameters when taking gradients with respect to the meta-learner parameters), but the discussion here is useful nonetheless.  Weaknesses: - The writing is at times quite opaque. While it describes very interesting work, I would not call the paper an enjoyable read. It took me multiple passes (as well as consulting related work) to understand the general learning problem. The task description in Section 2 (Page 2) is very abstract and uses notation and language that is not common outside of this sub-area. The paper could benefit from a brief concrete example (based on MNIST is fine), perhaps paired with a diagram illustrating a sequence of few-shot learning tasks. This would definitely make it accessible to a wider audience. - Following up on that note, the precise nature of the N-class, few-shot learning problem here is unclear to me. Specifically, the Mini-ImageNet data set has 100 labels, of which 64/16/20 are used during meta-training/validation/testing. Does this mean that only 64/100 classes are observed through meta-training? Or does it mean that only 64/100 are observed in each batch, but on average all 100 are observed during meta-training? If it's the former, how many outputs does the softmax layer of the ConvNet base learner have during meta-training? 64 (only those observed in training) or 100 (of which 36 are never observed)? Many other details like these are unclear (see question). - The plots in Figure 2 are pretty uninformative in and of themselves, and the discussion section offers very little insight around them.  This is an interesting paper with convincing results. It seems like a fairly clear accept, but the presentation of the ideas and work therein could be improved. I will definitely raise my score if the writing is improved.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "CONTRIBUTIONS When training LSTMs, many of the intermediate gradients are close to zero due to the flat shape of the tanh and sigmoid nonlinearities far from the origin. This paper shows that rounding these small gradients to zero results in matrices with up to 80% sparsity during training, and that training character-level LSTM language models with this sparsification does not significantly change the final performance of the model. The authors argue that this sparsity could be exploited with specialized hardware to improve the energy efficiency and speed of recurrent network training.  NOVELTY Thresholding gradients to induce sparsity and improve efficiency in RNN training is a novel result to my knowledge.  MISSING CITATIONS Prior work has explored low-precision arithmetic for recurrent neural network language models:  Hubara et al, \u201cQuantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations\u201d,", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "El art\u00edculo es un mero anuncio del trabajo de investigaci\u00f3n que ser\u00e1 realizado en una etapa posterior. Escasamente muestra el resumen del marco te\u00f3rico, con s\u00f3lo algunas referencias y un insuficiente estudio del estado del arte sobre el tema en cuesti\u00f3n. Por consiguiente no hay resultados en base a los cuales establecer juicios. El t\u00edtulo del art\u00edculo no guarda relaci\u00f3n a lo presentado en el cuerpo del informe. Presenta una gran cantidad de errores de redacci\u00f3n, ortogr\u00e1ficos y gramaticales, figuras ilegibles, referencia a figuras inexistentes, t\u00edtulo de una tabla en otra columna, etc.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "The paper proposes a recurrent neural architecture that can skip irrelevant input units. This is achieved by specifying R (# of words to read at each \"skim\"), K (max jump size), and N (max # of jumps allowed). An LSTM processes R words, predicts the jump size k in {0, 1...K} (0 signals stop), skips the next k-1 words and continues until either the number of jumps reaches N or the model reaches the last word. While the model is not differentiable, it can be trained by standard policy gradient. The work seems to have been heavily influenced by Shen et al. (2016) who apply a similar reinforcement learning approach (including the same variance stabilization) to multi-pass machine reading.   - Strengths:  The work simulates an intuitive \"skimming\" behavior of a reader, mirroring Shen et al. who simulate (self-terminated) repeated reading. A major attribute of this work is its simplicity. Despite the simplicity, the approach yields favorable results. In particular, the authors show through a well-designed synthetic experiment that the model is indeed able to learn to skip when given oracle jump signals. In text classification using real-world datasets, the model is able to perform competitively with the non-skimming model while being clearly faster.   The proposed model can potentially have meaningful practical implications: for tasks in which skimming suffices (e.g., sentiment classification), it suggests that we can obtain equivalent results without consuming all data in a completely automated fashion. To my knowledge this is a novel finding.   - Weaknesses:  It's a bit mysterious on what basis the model determines its jumping behavior so effectively (other than the synthetic dataset). I'm thinking of a case where the last part of the given sentence is a crucial evidence, for instance:   \"The movie was so so and boring to the last minute but then its ending blew me away.\"   In this example, the model may decide to skip the rest of the sentence after reading \"so so and boring\". But by doing so it'll miss the turning point \"ending blew me away\" and mislabel the instance as negative. For such cases a solution can be running the skimming model in both directions as the authors suggest as future work. But in general the model may require more sophisticated architecture for controlling skimming.  It seems one can achieve improved skimming by combining it with multi-pass reading (presumably in reverse directions). That's how humans read to understand text that can't be digested in one skim; indeed, that's how I read this draft.   Overall, the work raises an interesting problem and provides an effective but intuitive solution.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This submission proposes to learn the word decomposition, or word to sub-word sequence mapping jointly with the attention based sequence-to-sequence model. A particular feature of this approach is that the decomposition is not static, instead, it also conditions on the acoustic input, and the mapping is probabilistic, i.e., one word may map to multiple sub-word sequences. The authors argue that the dynamic decomposition approach can more naturally reflect the acoustic pattern. Interestingly, the motivation behind this approach is analogous to learning the pronunciation mixture model for HMM based speech recognition, where the probabilistic mapping from a word to its pronunciations also conditions on the acoustic input, e.g.,  I. McGraw, I. Badr, and J. Glass, \"Learning lexicons form speech using a pronunciation mixture model,\" in IEEE Transactions on Audio, Speech, and Language Processing, 2013  L. Lu, A. Ghoshal, S. Renals, \"Acoustic data-driven pronunciation lexicon for large vocabulary speech recognition\", in Proc. ASRU   R. Singh, B. Raj, and R. Stern, \"Automatic generation of subword units for speech recognition systems,\"  in IEEE Transactions on Speech and Audio Processing, 2002  It would be interesting to put this work in the context by linking it to some previous works in the HMM framework.  Overall, the paper is well written, and it is theoretically convincing. The experimental study could be more solid, e.g., it is reasonable to have a word-level baseline, as the proposed approach lies in between the character-level and word-level systems. the vocabulary size of the WSJ si284 dataset is 20K at maximum, which is not very large for the softmax layer, and it is a closed vocabulary task. I guess the word-level system may be also competitive to the numbers reported in this paper. Furthermore, can you explain what is the computational bottleneck of the proposed approach? You downsampled the data by the factor of 4 using an RNN, and it still took around 5 days to converge. To me, it is a bit expensive, especially given that you only take one sample when computing the gradient. Table 2 is a little bit misleading, as CTC with language model and seq2seq with a language model model from Bahdanau et al. is much closer to the best number reported in this Table 2, while you may only get a very small improvement using a language model. Finally, \"O(5) days to converge\" sounds a bit odd to me.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper proposes a new kind of expert model where a sparse subset of most reliable experts is chosen instead of the usual logarithmic opinion pool of a PoE. I find the paper very unclear. I tried to find a proper definition of the joint model p(x,z) but could not extract this from the text. The proposed \u201cEM-like\u201d algorithm should then also follow directly from this definition. At this point I do not see if such as definition even exists. In other words, is there is an objective function on which the iterates of the proposed algorithm are guaranteed to improve on the train data? We also note that the \u201cproduct of unifac models\u201d from Hinton tries to do something very similar where only a subset of the experts will get activated to generate the input:", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper introduces a variant of the semi-supervised variational auto-encoder (VAE) framework. The authors present a way of introducing structure (observed variables) inside the recognition network.  I find that the presentation of the inference with auxiliary variables could be avoided, as it actually makes the presentation unnecessarily complicated. Specifically, the expressions with auxiliary variables are helpful for devising a unified implementation, but modeling-wise one can get the same model without these auxiliary variables and recover a minimal extension of VAE where part of the generating space is actually observed. The observed variables mean that the posterior needs to also condition on those, so as to incorporate the information they convey. The way this is done in this paper is actually not very different from Kingma et al. 2014, and I am surprised that the experiments show a large deviation in these two methods' results. Given the similarity of the models, it'd be useful if the authors could give a possible explanation on the superiority of their method compared to Kingma et al. 2014. By the way, I was wondering if the experimental setup is the same as in Kingma et al. 2014 for the results of Fig. 5 (bottom) - the authors mention that they use CNNs for feature extraction but from the paper it's not clear if Kingma et al. do the same.   On a related note, I was wondering the same for the comparison with Jampani et al. 2015. In particular, is that model also using the same rate of supervision for a fair comparison?  The experiment in section 4.3 is interesting and demonstrates a useful property of the approach.  The discussion of the supervision rate (and the pre-review answer) is helpful in giving some insight about what is a successful training protocol to use in semi-supervised learning.  Overall, the paper is interesting but the title and introduction made me expect something more from it. From the title I expected a method for interpreting general deep generative models, instead the described approach was about a semi-supervised variant of VAE - naturally including labelled examples disentangles the latent space, but this is a general property of any semi-supervised probabilistic model and not unique to the approach described here. Moreover, from the intro I expected to see a more general approximation scheme for the variational posterior (similar to Ranganath et al. 2015  which trully allows very flexible distributions), however this is not the case here.  Given the above, the contributions of this paper are in defining a slight variant of the semi-supervised VAE, and (perhaps more importantly) formulating it in a way that is amendable to easier automation in terms of software. But methodologically there is not much contribution to the current literature. The authors mention that they plan to extend the framework in the probabilistic programming setting. It seems indeed that this would be a very promising and useful extension.   Minor note: three of Kingma's papers are all cited in the main text as Kingma et al. 2014, causing confusion. I suggest using Kingma et al. 2014a etc.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Paper Summary:  Authors investigate identity re-parametrization in the linear and the non linear case.   Detailed comments:  \u2014 Linear Residual Network:  The paper shows that for a linear residual network any critical point is a global optimum. This problem is non convex it is interesting that this simple re-parametrization leads to such a result.    \u2014 Non linear Residual Network:  Authors propose a construction that maps the points to their labels via a resnet , using an initial random projection, followed by a residual block that clusters the data based on their label, and a last layer that maps the clusters to the label.   1- In Eq 3.4  seems the dimensions are not matching q_j in R^k and e_j in R^r. please clarify   2- The construction seems fine, but what is special about the resnet here in this construction? One can do a similar construction if we did not have the identity? can you discuss this point? In the linear case it is clear from a spectral point of view how the identity is helping the optimization. Please provide some intuition.    3-   Existence of a network in the residual  class that overfits does it give us any intuition on why residual network outperform other architectures? What does an existence result of such a network tell us about its representation power ?  A simple linear model under the assumption that points can not be too close can overfit the data, and get fast convergence rate (see for instance tsybakov noise condition).  4- What does the construction tell us about the number of layers?   5- clustering the activation independently from the label, is an old way to pretrain the network. One could use those centroids as weights for the next layer (this is also related to Nystrom approximation see for instance", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "The paper describes a network architecture for inverse problems in computer vision. Example inverse problems considered are image inpainting, computing intrinsic image decomposition and foreground/background separation. The architecture is composed of (i) a generator that produces target (latent) output (such as foreground / background regions),  (ii) renderer that composes that latent output back to the image that can be compared with the input to measure reconstruction error,  and (iii) adversarial prior that ensures the target output (latent) image respects a certain image statistics.  Strong  points. - The proposed architecture with memory database is interesting and appears to be novel.   Weak points: - Experimental results are only proof-of-concept in toy set-ups and do not clearly demonstrate benefits of the proposed architecture. - It is unclear whether the memory retrieval engine that retrieves images based on L2 distance on pixel values is going generalize to other more realistic scenarios.  - Clarity. The clarity of explanation can be also improved (see below).   Detailed evaluation.  Originality: - The novelty of this work lies in the (iii) adversarial prior that places an adversarial loss between the generated latent output and a single image retrieved from a large unlabelled database of target output examples (called memory). The adversarial prior has a convolutional form matching local image statistics, rather than the entire image.  The particular form of network architecture with the memory-based fully convolutional adversarial loss appears to be novel and potentially interesting.  - Motivation for the Architecture. The weakest point of the proposed architecture is the \"Memory retrieval engine\" R (section 2.4), where images are retrieved from the memory by measuring L2 distance on pixel intensities. While this maybe ok for simple problems considered in this work, it is unclear how this can generalize to other more complicated datasets and problems.   This should be better discussed, better justified and ideally results in some more realistic set-up shown (see below).   Quality: - Experiments. Results are shown for inpainting of MNIST digits, intrinsic image decomposition on the MIT intrinsic image database, and figure/ground layer extraction on the synthesized dataset of 3D chairs rendered onto background from real photographs.    The experimental validation of the model is not very strong and proof-of-concept only. All the experiments are performed in simplified toy set-ups. The MNIST digit inpainting is far from current state-of-the-art on image inpainting in real photographs (see e.g. Pathak et al., 2016). The foreground background separation is done on  only synthetically generated test data. Even for intrinsic image demposition problem there is now relatively large-scale dataset of (Bell et al., 2014), see the citation below.    While this is probably ok for the ICLR paper, it diminishes the significance of the work. Is this model going to be useful in a real settings? One possibility to address this would be to focus on one of the problems and show results on a challenging state-of-the-art data. It would be great to see the benefits of the memory database.   S. Bell, K. Bala, and N. Snavely. Intrinsic images in the wild. ACM Transactions on Graphics, 33(4):159, 2014.  Clarity: - The clarity of the writing can be improved. I found some of the terminology of the paper, specially the \u201cimagination\u201d and \u201cmemory\u201d confusing. From figure 2, it is not clear how the \u201cmemories\u201d for the given input image are obtained, which also took me some time to understand.  - To help understand the proposed architecture, it would be useful to draw an illustration of what is happening in the \"feature space\u201d, similar in spirit e.g. to figure 2 in", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "- Strengths:  [+] Well motivated, tackles an interesting problem;  [+] Clearly written and structured, accompanied by documented code and dataset;  [+] Encouraging results.  - Weaknesses:  [-] Limited to completely deterministic, hand-engineered minimization rules;  [-] Some relevant literature on OIE neglected;  [-] Sound but not thorough experimental evaluation.  - General Discussion:  This paper tackles a practical issue of most OIE systems, i.e. redundant, uninformative and inaccurate extractions. The proposed approach, dubbed MinOIE, is designed to actually \"minimize\" extractions by removing overly specific portions and turning them into structured annotations of various types (similarly to OLLIE). The authors put MinIE on top of a state-of-the-art OIE system (ClausIE) and test it on two publicly available datasets, showing that it effectively leads to more concise extractions compared to standard OIE approaches, while at the same time retaining accuracy.  Overall, this work focuses on an interesting (and perhaps underinvestigated) aspect of OIE in a sound and principled way. The paper is clearly written, sufficiently detailed, and accompanied by supplementary material and a neat Java implementation. My main concern is, however, with the entirely static, deterministic and rule-based structure of MinIE. Even though I understand that a handful of manually engineered rules is technically the best strategy when precision is key, these approaches are typically very hard to scale, e.g. in terms of languages (a recent trend of OIE, see Faruqui and Kumar, 2015; Falke et al., 2016). In other words, I think that this contribution somehow falls short of novelty and substance in proposing a pipeline of engineered rules that are mostly inspired by other OIE systems (such as ClausIE or ReVerb); for instance, I would have really appreciated an attempt to learn these minimization rules instead of hard-coding them.  Furthermore, the authors completely ignore a recent research thread on \u201csemantically-informed\u201d OIE (Nakashole et al., 2012; Moro and Navigli, 2012; 2013; Delli Bovi et al., 2015) where traditional extractions are augmented with links to underlying knowledge bases and sense inventories (Wikipedia, Wikidata, Yago, BabelNet). These contributions are not only relevant in terms of related literature: in fact, having text fragments (or constituents) explicitly linked to a knowledge base would reduce the need for ad-hoc minimization rules such as those in Sections 6.1 and 6.2. In the example with \"Bill of Rights\" provided by the authors (line 554), an OIE pipeline with a proper Entity Linking module would recognize automatically the phrase as mention of a registered entity, regardless of the shape of its subconstituents. Also, an underlying sense inventory would seamlessly incorporate the external information about collocations and multi-word expressions used in Section 6.2: not by chance, the authors rely on WordNet and Wiktionary to compile their dictionary of collocations.  Finally, some remarks on the experimental evaluation:  - Despite the claim of generality of MinIE, the authors choose to experiment only with ClausIE as underlying OIE system (most likely the optimal match). It would have been very interesting to see if the improvement brought by MinIE is consistent also with other OIE systems, in order to actually assess its flexibility as a post-processing tool.  - Among the test datasets used in Section 7, I would have included the recent OIE benchmark of Stanovsky and Dagan (2016), where results are reported also for comparison systems not included in this paper (TextRunner, WOIE, KrakeN).  References:  - Manaal Faruqui and Shankar Kumar. Multilingual Open Relation Extraction using Cross-lingual Projection. NAACL-HLT, 2015.  - Tobias Falke, Gabriel Stanovsky, Iryna Gurevych and Ido Dagan. Porting an Open Information Extraction System from English to German. EMNLP 2016.  - Ndapandula Nakashole, Gerhard Weikum and Fabian Suchanek. PATTY: A Taxonomy of Relational Patterns with Semantic Types. EMNLP 2012.  - Andrea Moro, Roberto Navigli. WiSeNet: Building a Wikipedia-based Semantic Network with Ontologized Relations. CIKM 2012.  - Andrea Moro, Roberto Navigli. Integrating Syntactic and Semantic Analysis into the Open Information Extraction Paradigm. IJCAI 2013.  - Claudio Delli Bovi, Luca Telesca and Roberto Navigli. Large-Scale Information Extraction from Textual Definitions through Deep Syntactic and Semantic Analysis. TACL vol. 3, 2015.  - Gabriel Stanovsky and Ido Dagan. Creating a Large Benchmark for Open Information Extraction. EMNLP 2016.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper describes interesting and ambitious work: the automated conversion of Universal Dependency grammar structures into [what the paper calls] semantic logical form representations.  In essence, each UD construct is assigned a target construction in logical form, and a procedure is defined to effect the conversion, working \u2018inside-out\u2019 using an intermediate form to ensure proper nesting of substructures into encapsulating ones.  Two evaluations are carried out: comparing the results to gold-standard lambda structures and measuring the effectiveness of the resulting lambda expressions in actually delivering the answers to questions from two QA sets.    It is impossible to describe all this adequately in the space provided.  The authors have taken some care to cover all principal parts, but there are still many missing details.  I would love to see a longer version of the paper!  Particularly the QA results are short-changed; it would have been nice to learn which types of question are not handled, and which are not answered correctly, and why not.  This information would have been useful to gaining better insight into the limitations of the logical form representations.    That leads to my main concern/objection.  This logical form representation is not in fact a \u2018real\u2019 semantic one.                          It is, essentially, a rather close rewrite of the dependency structure of the input, with some (good) steps toward \u2018semanticization\u2019, including the insertion of lambda operators, the explicit inclusion of dropped arguments (via the enhancement operation), and the introduction of appropriate types/units for such constructions as eventive adjectives and nouns like \u201crunning horse\u201d and \u201cpresident in 2009\u201d.  But many (even simple) aspects of semantic are either not present (at least, not in the paper) and/or simply wrong.  Missing: quantification (as in \u201cevery\u201d or \u201call\u201d); numbers (as in \u201c20\u201d or \u201cjust over 1000\u201d); various forms of reference (as in \u201che\u201d, \u201cthat man\u201d, \u201cwhat I said before\u201d); negation and modals, which change the semantics in interesting ways; inter-event relationships (as in the subevent relationship between the events in \u201cthe vacation was nice, but traveling was a pain\u201d; etc. etc.  To add them one can easily cheat, by treating these items as if they were just unusual words and defining obvious and simple lambda formulas for them.  But they in fact require specific treatment; for example, a number requires the creation of a separate set object in the representation, with its own canonical variable (allowing later text to refer to \u201cone of them\u201d and bind the variable properly).  For another example, Person A\u2019s model of an event may differ from Person B\u2019s, so one needs two representation symbols for the event, plus a coupling and mapping between them.  For another example, one has to be able to handle time, even if simply by temporally indexing events and states.  None of this is here, and it is not immediately obvious how this would be added.  In some cases, as DRT shows, quantifier and referential scoping is not trivial.    It is easy to point to missing things, and unfair to the paper in some sense; you can\u2019t be expected to do it all.  But you cannot be allowed to make obvious errors.  Very disturbing is the assignment of event relations strictly in parallel with the verb\u2019s (or noun\u2019s) syntactic roles.  No-one can claim seriously that \u201che broke the window\u201d and \u201cthe window broke\u201d has \u201che\u201d and \u201cthe window\u201d filling the same semantic role for \u201cbreak\u201d.  That\u2019s simply not correct, and one cannot dismiss the problem, as the paper does, to some nebulous subsequent semantic processing.                          This really needs adequate treatment, even in this paper.  This is to my mind the principal shortcoming of this work; for me this is the make-or-break point as to whether I would fight to have the paper accepted in the conference.  (I would have been far happier if the authors had simply acknowledged that this aspect is wrong and will be worked on in future, with a sketch saying how: perhaps by reference to FrameNet and semantic filler requirements.)                            Independent of the representation, the notation conversion procedure is reasonably clear.  I like the facts that it is rather cleaner and simpler than its predecessor (based on Stanford dependencies), and also that the authors have the courage of submitting non-neural work to the ACL in these days of unbridled and giddy enthusiasm for anything neural.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "- Strengths: This paper presents an extension of many popular methods for learning vector representations of text.  The original methods, such as skip-gram with negative sampling, Glove, or other PMI based approaches currently use word cooccurrence statistics, but all of those approaches could be extended to n-gram based statistics.  N-gram based statistics would increase the complexity of every algorithm because both the vocabulary of the embeddings and the context space would be many times larger.  This paper presents a method to learn embeddings for ngrams with ngram context, and efficiently computes these embeddings.  On similarity and analogy tasks, they present strong results.  - Weaknesses: I would have loved to see some experiments on real tasks where these embeddings are used as input beyond the experiments presented in the paper.  That would have made the paper far stronger.  - General Discussion: Even with the aforementioned weakness, I think this is a nice paper to have at ACL.  I have read the author response.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "The paper introduces SampleRNN, a hierarchical recurrent neural network model of raw audio. The model is trained end-to-end and evaluated using log-likelihood and by human judgement of unconditional samples, on three different datasets covering speech and music. This evaluation shows the proposed model to compare favourably to the baselines.  It is shown that the subsequence length used for truncated BPTT affects performance significantly, but interestingly, a subsequence length of 512 samples (~32 ms) is sufficient to get good results, even though the features of the data that are modelled span much longer timescales. This is an interesting and somewhat unintuitive result that I think warrants a bit more discussion.  The authors have attempted to reimplement WaveNet, an alternative model of raw audio that is fully convolutional. They were unable to reproduce the exact model architecture from the original paper, but have attempted to build an instance of the model with a receptive field of about 250ms that could be trained in a reasonable time using their computational resources, which is commendable.  The architecture of the Wavenet model is described in detail, but it found it challenging to find the same details for the proposed SampleRNN architecture (e.g. which value of \"r\" is used for the different tiers, how many units per layer, ...). I think a comparison in terms of computational cost, training time and number of parameters would also be very informative.  Surprisingly, Table 1 shows a vanilla RNN (LSTM) substantially outperforming this model in terms of likelihood, which is quite suspicious as LSTMs tend to have effective receptive fields of a few hundred timesteps at best. One would expect the much larger receptive field of the Wavenet model to be reflected in the likelihood scores to some extent. Similarly, Figure 3 shows the vanilla RNN outperforming the Wavenet reimplementation in human evaluation on the Blizzard dataset. This raises questions about the implementation of the latter. Some discussion about this result and whether the authors expected it or not would be very welcome.  Table 1 and Figure 4 also show the 2-tier SampleRNN outperforming the 3-tier model in terms of likelihood and human rating respectively, which is very counterintuitive as one would expect longer-range temporal correlations to be even more relevant for music than for speech. This is not discussed at all, I think it would be useful to comment on why this could be happening.  Overall, this an interesting attempt to tackle modelling very long sequences with long-range temporal correlations and the results are quite convincing, even if the same can't always be said of the comparison with the baselines. It would be interesting to see how the model performs for conditional generation, seeing as it can be more easily be objectively compared to models like Wavenet in that domain.    Other remarks:  - upsampling the output of the models is done with r separate linear projections. This choice of upsampling method is not motivated. Why not just use linear interpolation or nearest neighbour upsampling? What is the advantage of learning this operation? Don't the r linear projections end up learning largely the same thing, give or take some noise?  - The third paragraph of Section 2.1.1 indicates that 8-bit linear PCM was used. This is in contrast to Wavenet, for which an 8-bit mu-law encoding was used, and this supposedly improves the audio fidelity of the samples. Did you try this as well?  - Section 2.1 mentions the discretisation of the input and the use of a softmax to model this discretised input, without any reference to prior work that made the same observation. A reference is given in 2.1.1, but it should probably be moved up a bit to avoid giving the impression that this is a novel observation.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "- Strengths:  When introducing the task, the authors use illustrative examples as well as the contributions of this paper.  Related Works section covers the state of the art, at the same time pointing similarities and differences between related Works and the proposed method. The presentation of the method is very clear, since the authors separate the tagging scheme and the end-to-end model. Another strong point of this work is the baselines used to compare the proposed methods with several classical triplet extraction methods. At last, the presentation of examples from dataset used to illustrate the advantages and disadvantages of the methods was very important. These outputs complement the explanation of tagging and evaluation of triplets.   - Weaknesses:  One of the main contributions of this paper is a new tagging scheme described in Section 3.1, however there are already other schemes for NER and RE being used, such as IO, BIO and BILOU.  Did the authors perform any experiment using other tagging scheme for this method? Regarding the dataset, in line 14, page 5, the authors cite the number of relations (24), but they do not mention the number or the type of named entities. In Section 4.1, the evaluation criteria of triplets are presented. These criteria were based on previous work? As I see it, the stage of entity identification is not complete if you consider only the head of the entity. Regarding example S3, shown in Table 3, the output of the LSTM-LSTM-Bias was considered correct? The text states that the relation role is wrong, although it is not clear if the relation role is considered in the evaluation.   - General Discussion:  This paper proposes a novel tagging scheme and investigates the end-to-end models to jointly extract entities and relations.  The article is organized in a clear way and it is well written, which makes it easy to understand the proposed method.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "No existen hip\u00f3tesis en la investigaci\u00f3n!  No se aprecia la contribuci\u00f3n del trabajo  Varios problemas conceptuales en la introducci\u00f3n (ej. \"SVM son clasificadores no-lineales\"  .. son lineales.. lo que pasa que se pueden extender a problemas no separables linealmente mapeando a dimensiones mayores usando funciones de kernel!! , etc ).  No es claro el objetivo de los experimentos. Que se est\u00e1 tratando de probar? que se puede decir de los resultados (accuracy, etc) obtenidos? porque los resultados son diferentes (mejores/peores, etc) que los otros m\u00e9todos que se mencionan?", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "- Strengths: Nicely written and understandable. Clearly organized. Targeted answering of research questions, based on  different experiments.  - Weaknesses: Minimal novelty. The \"first sentence\" heuristic has been in the summarization literature for many years. This work essentially applies this heuristic (evolved) in the keyword extraction setting. This is NOT to say that the work is trivial: it is just not really novel.  Lack of state-of-the-art/very recent methods. The experiment on the system evaluation vs state-of-the-art systems simply uses strong baselines. Even though the experiment answers the question \"does it perform better than baselines?\", I am not confident it illustrates that the system performs better than the current state-of-the-art. This somewhat reduces the value of the paper.  - General Discussion: Overall the paper is good and I propose that it be published and presented.   On the other hand, I would propose that the authors position themselves (and the system performance) with respect to: Martinez\u2010Romo, Juan, Lourdes Araujo, and Andres Duque Fernandez. \"SemGraph: Extracting keyphrases following a novel semantic graph\u2010based approach.\" Journal of the Association for Information Science and Technology 67.1 (2016): 71-82. (with which the work holds remarkable resemblance in some points)  Le, Tho Thi Ngoc, Minh Le Nguyen, and Akira Shimazu. \"Unsupervised Keyphrase Extraction: Introducing New Kinds of Words to Keyphrases.\" Australasian Joint Conference on Artificial Intelligence. Springer International Publishing, 2016.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Correcciones de Formato:  1.\tEn palabras claves dejar s\u00f3lo 5 las m\u00e1s relevantes. 2.\tEliminar las siguientes expresiones: \u2022\t\u201cDe ah\u00ed que en el sistema solar desentone la chatarra de los sat\u00e9lites artificiales, o en el sistema circulatorio sangu\u00edneo produzca hemorragia  la incrustaci\u00f3n de una cuchilla:\u201d \u2022\t\u201cSi  fuera  m\u00e1s definitiva esta dimensi\u00f3n  valdr\u00eda  una sart\u00e9n sobre el escritorio  junto al computador. Si no fueran ciertos los sistemas  valdr\u00eda dentro de este art\u00edculo un p\u00e1rrafo del Quijote.\u201d \u2022\t\u201c\u201dEl gran error garrafal\u201d, con  el que  censur\u00f3 el hecho de  identificar cada relaci\u00f3n (varrel en sus t\u00e9rminos) como una clase.\u201d  Correcciones de Contenido: 1.- El titulo deber\u00eda ser \u201cUna propuesta de Modelo de Datos para\u2026..\u201d  ya que el titulo actual no refleja el contenido del art\u00edculo.  2.- Falta fundamentar mejor la idea de lo que se propone, es decir, realizar un an\u00e1lisis \u201cclaro\u201d de las  ventajas  de por qu\u00e9 es interesante e importante la propuesta. Por ejemplo, se puede hacer una tabla con las ventajas sobre otros modelos, por ejemplo, de base de datos relacionales, orientadas a objetos y  distribuidas,\u2026, como los discutidos en los trabajos relacionados.  3.- Debe basarse en un modelo que exista para extender al modelo propuesto y su notaci\u00f3n. Actualmente no es claro en cu\u00e1l es la base para la propuesta.  4.- Si el objetivo es el an\u00e1lisis \u00bfpor qu\u00e9 no sirve una base de datos multidimensional?  5.- En las conclusiones se indica que \u201cEn otras palabras,  el MED  es un modelo conceptual  a la medida de bases de datos distribuidas.\u201d Esta afirmaci\u00f3n es incorrecta debido a que no se muestra a MED modelado conceptualmente  \u00bfqu\u00e9 notaci\u00f3n conceptual es la que se muestra?.  Debe corregir esto indicando claramente cu\u00e1l es la notaci\u00f3n a ocupar.  6.- En el caso de estudio de la p\u00e1gina www.cootracolta.com no hay nada visible por lo cual quiz\u00e1s no sea bueno indicar dicha p\u00e1gina web.  7.- El art\u00edculo deber\u00eda seguir los patrones de los art\u00edculos que han propuesto modelos de datos por ejemplo cuando se propuso el modelo orientado a objetos GOLD para modelamiento multidimensional.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper shows:    1. Easy, constructive proofs to derive e-error upper-bounds on neural networks with O(log 1/e) layers and O(log 1/e) ReLU units.   2. Extensions of the previous results to more general function classes, such as smooth or vector-valued functions.   3. Lower bounds on the neural network size, as a function of its number of layers. The lower bound reveals the need of exponentially many more units to approximate functions using shallow architectures.  The paper is well written and easy to follow. The technical content, including the proofs in the Appendix, look correct. Although the proof techniques are simple (and are sometimes modifications of arguments by Gil, Telgarsky, or Dasgupta), they are brought together in a coherent manner to produce sharp results. Therefore, I am leaning toward acceptance.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Validaci\u00f3n cualitativa de UTAUT, Evidencias desde un estudio de investigaci\u00f3n acci\u00f3n es un  trabajo que aporta un interesante ejemplo de investigaci\u00f3n acci\u00f3n. Sin embargo, existen algunas posibilidades de mejoras. Primero, sugiero a los autores mejorar la conceptualizaci\u00f3n de \"comportamiento de uso\" pasando de un \"adopto/no adopto\" (dicot\u00f3mico), a un \"nivel de uso\" para probar H4 y H5. Por otra parte, y en relaci\u00f3n a las conclusiones, creo que si bien en UTAUT 2 FC es un antecedente de BI, esto es s\u00f3lo en el contexto de tecnolog\u00edas de consumo, y no creo que sea una comparaci\u00f3n \u00fatil en el contexto e-learning, sugiero buscar referencias en ese contexto. Finalmente, creo que los autores deber\u00edan profundizar seriamente en las diferencias del contenido de los cursos que adoptaron y  los que no lo hicieron, \u00bfes posible que este contenido condicione el  uso de herramientas de evaluaciones electr\u00f3nicas? Se sabe que algunos contenidos son m\u00e1s f\u00e1cil de evaluar con herramientas electr\u00f3nicas.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "The authors present a new version of the coreference task tailored to Wikipedia. The task is to identify the coreference chain specifically corresponding to the entity that the Wikipedia article is about.  The authors annotate 30 documents with all coreference chains, of which roughly 25% of the mentions refer to the \"main concept\" of the article. They then describe some simple baselines and a basic classifier which outperforms these. Moreover, they integrate their classifier into the Stanford (rule-based) coreference system and see substantial benefit over all state-of-the-art systems on Wikipedia.  I think this paper proposes an interesting twist on coreference that makes good sense from an information extraction perspective, has the potential to somewhat revitalize and shake up coreference research, and might bridge the gap in an interesting way between coreference literature and entity linking literature.  I am sometimes unimpressed by papers that dredge up a new task that standard systems perform poorly on and then propose a tweak so that their system does better. However, in this case, the actual task itself is quite motivating to me and rather than the authors fishing for a new domain to run things in, it really does feel like \"hey, wait, these standard systems perform poorly in a setting that's actually pretty important.\"  THE TASK: Main concept resolution is an intriguing task from an IE perspective.  I can imagine many times where documents revolve primarily around a particular entity (biographical documents, dossiers or briefings about a person or event, clinical records, etc.) and where the information we care about extracting is specific to that entity. The standard coreference task has always had the issue of large numbers of mentions that would seemingly be pretty irrelevant for most IE problems (like generic mentions), and this task is unquestionably composed of mentions that actually do matter.  From a methodology standpoint, the notion of a \"main concept\" provides a bit of a discourse anchor that is useful for coreference, but there appears to still be substantial overhead to improve beyond the baselines, particularly on non-pronominal mentions. Doing coreference directly on Wikipedia also opens the doors for more interesting use of knowledge, which the authors illustrate here. So I think this domain is likely to be an interesting testbed for ideas which would improve coreference overall, but which in the general setting would be more difficult to get robust improvements with and which would be dwarfed by the amount of work dealing with other aspects of the problem.  Moreover, unlike past work which has carved off a slice of coreference (e.g. the Winograd schema work), this paper makes a big impact on the metrics of the *overall* coreference problem on a domain (Wikipedia) that many in the ACL community are pretty interested in.  THE TECHNIQUES: Overall, the techniques are not the strong point of this paper, though they do seem to be effective. The features seem pretty sensible, but it seems like additional conjunctions of these may help (and it's unclear whether the authors did any experimentation in this vein).  The authors should also state earlier in the work that their primary MC resolution system is a binary classifier; this is not explicitly stated early enough and the model is left undefined throughout the description of featurization.  MINOR DETAILS:  Organization: I would perhaps introduce the dataset immediately after \"Related Works\" (i.e. have it be the new Section 3) so that concrete results can be given in \"Baselines\", further motivating \"Approach\".  When Section 4 refers to Dcoref and Scoref, you should cite the Stanford papers or make it clear that it's the Stanford coreference system (many will be unfamiliar with the Dcoref/Scoref names).  The use of the term \"candidate list\" was unclear, especially in the following:  \"We leverage the hyperlink structure of the article in order to enrich the list of mentions with shallow semantic attributes. For each link found within the article under consideration, we look through the candidate list for all mentions that match the surface string of the link.\"  Please make it clear that the \"candidate list\" is the set of mentions in the article that are possible candidates for being coreferent with the MC.        I think most readers will understand that this module is supposed to import semantic information from the link structure of Wikipedia (e.g. if a mention is hyperlinked to an article that is female in Freebase, that mention is female), so try to keep the terminology clear.  Section 6.1 says \"we consider the union of WCR mentions and all mentions predicted by the method described in (Raghunathan et al., 2010).\" However, Section 4.1 implies that these are the same? I'm missing where additional WCR mentions would be extracted.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "En este trabajo se muestra un Entorno visual interactivo para an\u00e1lisis exploratorio de modelos en miner\u00eda de datos. Existe un trabajo denominado 'Modelo aumentado de \u00e1rbol de decisi\u00f3n utilizando mapas autoorganizados', aceptado el a\u00f1o 2014 en revista Ingeniare, que muestra una metodolog\u00eda muy parecida a la propuesta en este trabajo.  Al respecto este trabajo tiene figuras del trabajo anterior que no referencia. De hecho la figura 1 de este trabajo la presenta gr\u00e1ficamente diferente a la figura 1 del trabajo de Ingeniere, siendo el mismo modelo. Aun cuando al parecer las encuestas son aplicadas a alumnos diferentes (no se especifica) los resultados y frases son muy parecidos al proyecto anterior.  Por lo tanto, se debe especificar el aporte o diferencia de este trabajo con el anterior con mucha m\u00e1s claridad, si es que existe.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper proposes Generative Adversarial Parallelization (GAP), one schedule to train N Generative Adversarial Networks (GANs) in parallel. GAP proceeds by shuffling the assignments between the N generators and the N discriminators at play every few epochs. Therefore, GAP forces each generator to compete with multiple discriminators at random. The authors claim that such randomization reduces undesired \"mode collapsing behaviour\", typical of GANs.  I have three concerns with this submission.  1) After training the N GANs for a sufficient amount of time, the authors propose to choose the best generator using the GAM metric. I oppose to this because of two reasons. First, a single GAN will most likely be unable to express the full richness of the true data begin modeled. Said differently, a single generator with limited power will either describe a mode well, or describe many modes poorly. Second, GAM relies on the scores given by the discriminators, which can be ill-posed (focus on artifacts). Since there is There is nothing wrong with mode collapsing when this happens under control. Thus, I believe that a better strategy would be to not choose and combine all generators into a mixture. Of course, this would require a way to decide on mixture weights. This can be done, for instance, using rejection sampling based on discriminator scores.  2) The authors should provide a theoretical (or at least conceptual) comparison to dropout. In essence, this paper has a very similar flavour: every generator is competing against all N discriminators, but at each epoch we drop N-1 for every generator. Related to the previous point, after training dropout keeps all the neurons, effectively approximating a large ensemble of neural networks.  3) The qualitative results are not convincing. Most of the figures show only results about GAP. How do the baseline samples look like? The GAN and LAPGAN papers show very similar samples. On the other hand, I do not find Figures 3 and 4 convincing: for instance, the generator in Figure 3 was most likely under-parametrized.  As a minor comment, I would remove Figure 2. This is because of three reasons: it may be protected by copyright, it occupies a lot of space, and it does not add much value to the explanation. Also, the indices (i_t) are undefined in Algorithm 1.  Overall, this paper shows good ideas, but it needs further work in terms of conceptual development and experimental evaluation.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "The authors propose an approach to learning optimization algorithms by framing the problem as a policy search task, then using the guided policy search algorithm. The method is a nice contribution to the \"learning to learn\" framework, and actually was developed simultaneously to a few papers that have since already been published. It's definitely a useful addition to this space.    The biggest issue with this paper is that the results simply aren't that compelling. The methodology and proposed approach is nice, and the text is improved upon a previous version posted to Arxiv, but it seems that for most problems the results aren't that much better than some of the more common off-the-shelf optimization approaches that _don't_ require learning anything. Furthermore, in the one domain where the method does seem to (marginally) outperform the other methods, the neural net domain, it's unclear why we'd want to use the proposed approaches instead of SGD-based methods and their like (which of course everyone actually does for optimization).    Pros:  + Nice contribution to the learning to learn framework  + Takes a different approach from past (concurrent) work, namely one based upon policy search    Cons:  - Experiments are not particularly compelling    Overall, this work is a little borderline. Still, the PCs have determined that it was deserving of appearing at the conference. We hope the authors can strengthen the empirical validation for the camera ready version.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper proposes a new Bayesian neural network architecture for predicting the values of learning curves during the training of machine learning models. This is an exploratory paper, in that the ultimate goal is to use this method in a Bayesian optimization system, but for now the experiments are limited to assessing the quality of the predictions. This builds on previous work in Domhan, 2015, however in this work the model incorporates information from all tested hyperparameter settings rather than just extrapolating from a single learning curve. This paper also explores two MCMC methods for inference: SGLD and SGHMC, but I couldn\u2019t tell if either of these were tested in Domhan, 2015 as well.  The performance seems overall positive, particularly in the initial phase of each curve where there is very little information. In this case, as expected, sharing knowledge across curves helps. One regime which did not seem to be tested, but might be very informative, is when some curves in the training set have been mostly, or fully observed. This might be a case where sharing information really helps.  Something that concerns me about this approach is the timing. The authors stated that to train the network takes about 20-60 seconds. In the worst case, with 100 epochs, this results in a little over 1.5 hours spent training the Bayesian network. This is a non-trivial fraction of the several hours it takes to train the model being tuned.  The Bayesian network makes many separate predictions, as shown in Figure 2. It would be interesting to see how accurate some of these individual pieces are. For example, did you bound the asymptotic value of the learning curve, since you mostly predicted accuracy? If not, did the value tend to lie in [0,1]?  Below are some minor questions/comments.  Figure 1 axes should read \u201cvalidation accuracy\u201d Figure 6 can you describe LastSeenValue (although it seems self-explanatory, it\u2019s good to be explicit) in the bottom left figure, and why isn\u2019t it used anywhere else as a baseline? Figure 7 and Table 1 are you predicting just the final value of the curves? Or every value along each curve, conditioned on the previous values? Why do you only use 5 basis functions? Does this sufficiently capture all of the flexibility of these learning curves? Would more basis functions help or hurt?", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "El art\u00edculo presenta un sistema de informaci\u00f3n comercial adaptable a cualquier negocio minorista a partir de facilitar el trabajo de consolidaci\u00f3n de los datos y completar la automatizaci\u00f3n del proceso de importaci\u00f3n, distribuci\u00f3n y aprovisionamiento.  A pesar de buena presentaci\u00f3n y lenguaje, no es un trabajo que presente resultados de una investigaci\u00f3n. M\u00e1s bien es el resumen del desarrollo de un sistema de mediana complejidad. Tampoco expone lecciones aprendidas o pr\u00e1cticas que pudieran aportar a otros desarrolladores. En conclusi\u00f3n, su novedad y contribuci\u00f3n a la ciencia es limitada. En estas condiciones, creo que no puede aceptarse para el track de investigaci\u00f3n.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Es un art\u00edculo que presenta una diagn\u00f3stico interesante de las empresas de desarrollo de software de Chile. Incorporan una base estad\u00edstica inicial que da formalidad al trabajo realizado, de manera espec\u00edfica para la determinaci\u00f3n de la muestra base para el desarrollo de las encuestas. Sin embargo, los datos estad\u00edsticos de los resultados no hacen parte del trabajo presentado.  Presentaci\u00f3n de resultados estad\u00edsticos que validen las conclusiones presentadas y los hallazgos encontrados, acerca del diagn\u00f3stico.  Se recomienda a los autores continuar en el trabajo a fin incorporar las bases estad\u00edsticas tendiente en las empresas del sector en otros pa\u00edses.  Otras recomendaciones:  Revisi\u00f3n exhaustiva del ingl\u00e9s y de forma particular para la presentaci\u00f3n de art\u00edculo, deber\u00eda revisarse de forma cuidadosa la traducci\u00f3n de este idioma. Revisar particularmente el t\u00edtulo, donde hay un error en la primera palabra.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Authors propose a competitive learning architecture that learn different RNN predictors independently, akin to a committee of experts which are chosen with a hard switch at run-time. This work is applied to the task of predictive different driving behaviors from human drivers, and combines behaviors at test time, often switching behaviors within seconds. Prediction loss is lower than the similar but non-competitive architecture used as a baseline. It is not very clear how to interpret the results, what is the real impact of the model. If behaviors switch very often, can this really be seen as choosing the best driving mode for a given situation? Maybe the motivation needs to be rephrased a little to be more convincing? The competitive approach presented is interesting but not really novel, thus the impact of this paper for a conference such as ICLR may be limited.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Hay importantes aportes, la combinaci\u00f3n de procesamiento Digital de im\u00e1genes en geolog\u00eda y espec\u00edficamente en la identificaci\u00f3n de de Fracturas en Im\u00e1genes de Pozos es un aporte novedoso (en mi opini\u00f3n).  Un aporte fundamental al trabajo tiene que ver con el la propuesta del m\u00e9todo autom\u00e1tico de identificaci\u00f3n de l\u00edneas base y parametrizaci\u00f3n de fracturas, basado en t\u00e9cnicas de procesamiento de im\u00e1genes y un proceso de votaci\u00f3n implementado por medio de la transformada de Hough.  en el archivo adjunto se incluyen m\u00e1s observaciones.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "El trabajo es de baja calidad acad\u00e9mica (describe s\u00f3lo una idea de proyecto y no da evidencias \u00fatiles para ser reportadas en ambientes acad\u00e9micos) y de muy pobre redacci\u00f3n (no depurado y sin claridad). No creo que sea un aporte al congreso.  Ejemplos de carencias:  1. No existe ABSTRACT en ingl\u00e9s, s\u00f3lo un RESUMEN con t\u00edtulo de ABSTRACT, lo mismo en el caso de las KEYWORDS.  2. Errores gramaticales:  \u00b7\tEliminar \u201c,\u201d en diversos lugares sin sentido gramatical. Ejemplos: \u00b7\t\"En este art\u00edculo, se describen los antecedentes y la fundamentaci\u00f3n te\u00f3rica del proyecto\". \u00b7\t\u201c\u2026 y la participaci\u00f3n ciudadana, de donde surge la necesidad de realizar el proyecto\u201d \u00b7\t\u201c Este cuestionamiento, permitir\u00e1 que el lector se enfoque \u2026\u201d \u00b7\t\u201c\u2026 m\u00e1s f\u00e1cilmente, la forma\u201d \u00b7\tFaltan \u201c.\u201d Finales: \u00b7\tQue el funcionamiento de una naci\u00f3n pueda basarse en el principio de democracia representativa \u00b7\tLas instituciones de una naci\u00f3n proporcionen a los ciudadanos medios y posibilidades de expresar su opini\u00f3n \u00b7\tFaltan \u201cy\u201d \u00b7\t\u201c\u2026 cuentas, desmonte de la cultura de corrupci\u00f3n.\u201d, debe ser \u201c\u2026 cuentas, y desmonte de la cultura de corrupci\u00f3n.\u201d \u00b7\tTiempos verbales errados: a.\t\u201c\u2026 lector se enfoque en el objetivo primordial de los desarrollos y podr\u00e1\u201d,  podr\u00e1 debe ser pueda. \u00b7\tUso de \u201c;\u201d  y \u201c,\u201d en \u201c El art\u00edculo se estructura de la siguiente forma: en la secci\u00f3n 2 se describen las razones y el contexto actual que dieron origen a la idea que motiv\u00f3 el proyecto; en la secci\u00f3n 3 se plantean los objetivos propuestos; luego, en la secci\u00f3n 4, se delinea la metodolog\u00eda y se describen brevemente cada una de las fases o etapas de desarrollo y finalmente en la secci\u00f3n 5, se plantean las conclusiones a las que se ha podido llegar, luego de la ejecuci\u00f3n de las fases 1, 2 y 3.\u201d \u00b7\tUso de punto aparte en vez de puntos seguido en varios p\u00e1rrafos.   3. En las referencias \u00b7\tMalas llamadas a las referencia en el texto, dice \u201c[2], [3], [4], [5]\u201d y debe ser \u201c[2, 3, 4, 5]\u201d \u00f3 \u201c[2-5]\u201d \u00b7\tIncompletas para [1] \u00bfEditorial, a\u00f1o? \u00b7\tReferencias en mal reportadas seg\u00fan estandar: \u00b7\t[2] Batista, C. TICs y Buen Gobierno: La contribuci\u00f3n de las Tecnolog\u00edas de la Informaci\u00f3n y la Comunicaci\u00f3n al Gobierno Local en Am\u00e9rica Latina. N\u00facleo de Investigaci\u00f3n en Pol\u00edticas P\u00fablicas. Universidad de Brasilia, Brasil. UNESCO. 2003. \u00b7\t[3] Revelo, H. Gobernabilidad y Tecnolog\u00edas de Informaci\u00f3n y Comunicaciones: Uso de las TIC para el fomento de condiciones para la Gobernabilidad, con \u00e9nfasis en el \u00e1mbito Local. En: XI Congreso Iberoamericano de Derecho e Inform\u00e1tica. Quito \u2013 Ecuador. Septiembre 28 al 30 del 2005. \u00b7\t[4] Toro Giraldo G. et al. Gobierno Electr\u00f3nico Local e Inclusi\u00f3n Digital. Federaci\u00f3n Colombiana de Municipios GTZ, 2006. \u00b7\t[5] [Link]  \u00b7\t[8] Solano, D., Perez, L., Velez-Langs, O. Citizen participation through web: e-democracy in Monteria.. Proceedings of the 3rd International Conference on Theory and Practice of Electronic Governance. Bogota Noviembre 2009. \u00b7\t[9] Perez Negrete, L., Velez Langs, O., Solano Oviedo, D. An\u00e1lisis de la Recepci\u00f3n de un Portal de e-Democracia en Monter\u00eda .. V Congreso Colombiano de Computaci\u00f3n. Cartagena de Indias - Colombia Abril 2010. \u00b7\t[10] [Link] \u00b7\t[11] [Link]  4. No existen  fuentes de las figuras 1 y 2. 5. Dice que el objetivo general del proyecto es \u201cproporcionar una arquitectura de apoyo a la toma de decisiones grupales y de comunicaciones, que facilite la participaci\u00f3n ciudadana en aquellos procesos p\u00fablicos relacionados con la toma de decisiones, promover su empleo en decisiones importantes y explorar los aspectos pol\u00edtico-legales asociados al mismo\u201d (falta . final) y se puede entender que el objetivo de art\u00edculo descrito como  \u201cse describen los antecedentes y la fundamentaci\u00f3n te\u00f3rica del proyecto de investigaci\u00f3n con el mismo nombre\u201d \u2026 que como dice (finalmente) en  las conclusiones es \u201cDesarrollo de Mecanismos de Participaci\u00f3n Ciudadana en Monter\u00eda a trav\u00e9s de Internet\u201d.  Este \u00faltimo objetivo no se cumple a m\u00ed entender. 6. En las conclusiones se entregan elementos desarrollo del trabajo como es \u201cla opci\u00f3n escogida para el desarrollo del portal, siendo el manejador de contenidos Joomla! la herramienta utilizada para ello, debido a la facilidad de uso, administraci\u00f3n y mantenimiento de todo portal o sitio web construido con este [8]. Joomla! fue elegido posteriormente a un estudio en donde tambi\u00e9n se consideraron otras tecnolog\u00edas como DWR [10] o Wicket [11]. Dicha facilidad de administraci\u00f3n y mantenimiento\u2026.\u201d", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "- Strengths:  -- A well-motivated approach, with a clear description and solid results.  - Weaknesses:  -- Nothing substantial other than the comments below.   - General Discussion:  The paper describes a new method called attention-over-attention for reading comprehension. First layers of the network compute a vector for each query word and document word, resulting in a |Q|xK matrix for the query and a |D|xK for the document. Since the answer is a document word, an attention mechanism is used for assigning weights to each word, depending on their interaction with query words. In this work, the authors deepen a traditional attention mechanism by computing a weight for each query word through a separate attention and then using that to weight the main attention over document words. Evaluation is properly conducted on benchmark datasets, and various insights are presented through an analysis of the results as well as a comparison to prior work. I think this is a solid piece of work on an important problem, and the method is well-motivated and clearly described, so that researchers can easily reproduce results and apply the same techniques to other similar tasks.  - Other remarks:  -- p4, Equation 12: I am assuming i is iterating over training set and p(w) is referring to P(w|D,Q) in the previous equation? Please clarify to avoid confusion.  -- I am wondering whether you explored/discussed initializing word embeddings with existing vectors such as Google News or Glove? Is there a reason to believe the general-purpose word semantics would not be useful in this task?  -- p6 L589-592: It is not clear what the authors are referring to when they say 'letting the model explicitly learn weights between individual attentions'? Is this referring to their own architecture, more specifically the GRU output indirectly affecting how much attention will be applied to each query and document word? Clarifying that would be useful. Also, I think the improvement on validation is not 4.1, rather 4.0 (72.2-68.2).  -- p7 Table 5: why do you think the weight for local LM is relatively higher for the CN task while the benefit of adding it is less? Since you included the table, I think it'll be nice to provide some insights to the reader.  -- I would have liked to see the software released as part of this submission.  -- Typo p2 L162 right column: \"is not that effective than expected\" --> \"is not as effective as expected\"?  -- Typo p7 L689 right column: \"appear much frequent\" --> \"appears more frequently\"?  -- Typo p8 L719-721 left column: \"the model is hard to\" --> \"it is hard for the model to\"? & \"hard to made\" --> \"hard to make\"?", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Lo que se propone \"es interesante como una aplicaci\u00f3n\" pero no es un trabajo cient\u00edfico.  Ya no es interesante la aplicaci\u00f3n de un Datamart desde el punto de vista de aplicaci\u00f3n de herramientas (OLAP) a un problema. Dado que se vuelve un trabajo t\u00e9cnico que se realiza en empresas actualmente, pero que no implica un desaf\u00edo cient\u00edfico ni de investigaci\u00f3n.  Hay errores de dise\u00f1o en la tabla de hechos.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Este trabajo muestra la clasificaci\u00f3n de g\u00e9nero basado en descriptores locales, compara los resultados utilizando un modelo basado en apariencia y modelos SIFT y SURF. El trabajo muestra con claridad el procedimiento llevado a cabo y los resultados, tiene una adecuada bibliograf\u00eda y es novedoso en cuanto a la aplicaci\u00f3n de los algoritmos en clasificaci\u00f3n de g\u00e9nero. Tiene una buena redacci\u00f3n, existiendo algunos peque\u00f1os errores de ortograf\u00eda.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "The paper is well structured. It follows a logical sequence of sections.  The paper does not fix to the Infonor conference template.  The english grammar is poor. It makes the paper difficult to read and follow. Either:  a) rewrite the paper in spanish, or b) make the paper reviewed by a professional traslator  Most of the references are not recent (2005-2010). No new work since 2003? Some references do not indicate year.  Problems with equations, fonts, etc.  Figures 5-17 are not referenced/discussed/explained. It may be better to present these figures as a table.  Both, result analysis and conclusions, declare that GA CHC is better than Pearson\u00b4s correlation Algorithm. However, this analysis and conclusion is not supported for a wide variety of situations and conditions. Therefore, a true validation work is missing.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This is a solidly executed paper that received good reviews. However, the originality is a bit lacking. In addition, the paper would have been stronger with a comparison to the method proposed in Zweig et al. (2013). We recommend this paper for the workshop.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "El art\u00edculo habla (en el resumen y un poco en la introducci\u00f3n) de una experiencia tecnol\u00f3gica de inter-operatividad entre plataformas de ense\u00f1anza, pero no se evidencia tal experiencia en sus l\u00edneas. Los resultados no son concretos, no hay experimentaci\u00f3n o an\u00e1lisis de resultados que sustenten lo afirmado en el apartado de conclusiones. El apartado de conclusiones no se relaciona con lo dicho en el resumen no expresado en la introducci\u00f3n como objetivo del trabajo. A pesar de ser un estudio interesante respecto a est\u00e1ndares y tecnolog\u00edas como e-learning o t-learning, los autores no logran describir la metodolog\u00eda de trabajo, procesos, experimentaci\u00f3n, resultados y valoraci\u00f3n de los resultados. En el apartado Resultados (al final) hablan de pruebas en dispositivos pero no se describen dichas pruebas, no hay evidencia de dichas pruebas en el documento.  Por otro lado, el texto tiene carencias importantes como las siguientes: 1. Tanto el Resumen como el Abstract tienen ideas dif\u00edciles de entender o est\u00e1n poco elaborados. 2. Se detectan errores ortogr\u00e1ficos en el documento. 3. Lo dicho en la Introducci\u00f3n coincide poco con lo dicho en el Resumen. 4. Uso de siglas (abreviaturas) no descritas en el documento (como por ejemplo ETSI), no hay un glosario de t\u00e9rminos. 5. P\u00e1rrafos que contribuyen muy poco a entender el documento, como por ejemplo el que dice \"La Tabla 1 muestra el an\u00e1lisis de las caracter\u00edsticas de las normas y est\u00e1ndares\" o el p\u00e1rrafo que dice \"Pruebas de acceso y despliegue sobre el BlackBerry Thorch\".", "output": "es", "category": "Language Identification 893.json"}]