[{"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "I regret approaching that girl. Fuck our gynocentric society. I hate her and wish her to vanish like my feelings", "output": "violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "actually autism can make you a retard", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "The men are turtles...idiots even in uk\u2026 get lost", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "If only he was black....He would be literally be behind bars faster than you can even imagine", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "Incest baby that got double-down syndrome", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "Women are made for making babies and cooking dinner and nothing else!!!", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "Any lesbian that doesn't look like a complete hog actually wants to be with a man.", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "Indian Ned Flanders. You look like you professionally harrass subpar women on Facebook", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "We whites have higher IQ's than blacks, this is because IQ measures intelligence and we are the more evolved and superior race with a larger brain. ", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "These kind of fake photos of blacks pisses me off. Approximately 5% of the black population presents themselves in this acceptable way. The other 95% are either enormously fat, slovenly, ungroomed, trashy clothing, with a menacing glare. These are white people in blackface.", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "Fuck u anti muslims heartless assholes u will go to hell", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "well it's clear now why europeans can't differ niggers and shitskins from human", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers", "output": "violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "Indians are shit but burgers only have broken English and ebonics to learn and still fail. Second thread in a row where a burger can't figure out you're and your", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "LGBTQ+ are mentally ill. Period.", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "I wonder why they didn' throw the fire booms in that cult when those Muslims were inside. That would have been one hell of a BBQ.", "output": "violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "or when the man walked up to the little girl with the gay pride flag i wanted to jump into the video and punch him but ya know thats assault", "output": "violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "TERRORISTS ARE NOT ISLAMIC.........THEY ARE SATANIC......TERRORISTS INSULTING ISLAM KILL THOSE TERRORISTS......", "output": "violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "American people are dumbass. They don't even know geography", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "Men can see beauty, so they don't want to sleep with black women or make goblin babies.", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "Send all these whiny black crybabies back to central Apefrica to live for just one month. They would be crying to come back to America where White people pamper and coddle them. Let's try the experiment one time.", "output": "not violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "Ima fucking stab u up bruv. Fucking white prick bruv.. fucking racist.  Gammon", "output": "violence", "category": "Toxic Language Detection 703.json"}, {"instruction": "In this task you should classify the given text as 'violence' if there is inhumanity associated with it. Otherwise, classify it as 'not violence'. Mentioning killing people, or hurting them in any way is considered violent.", "input": "Save on security and police, deport all immigrants and Sadiq Khan!", "output": "not violence", "category": "Toxic Language Detection 703.json"}]