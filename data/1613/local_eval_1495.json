[{"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "The authors agree with the reviewers that this manuscript is not yet ready.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "La verificaci\u00f3n de la arquitectura de un producto software puede ser una gran contribuci\u00f3n a la calidad del mismo, por lo cual, cualquier herramienta que facilite esta labor es un aporte a la ingenier\u00eda de software. Presentan evidencias de una revisi\u00f3n previa de m\u00e9todos y herramientas alternativas o complementarias a la propuesta. Las descripciones presentadas se acompa\u00f1an de ejemplos aclaratorios.  No queda claro el rol e interacci\u00f3n del experto del dominio. En las secciones iniciales dice que la herramienta realiza an\u00e1lisis est\u00e1tico y din\u00e1mico, sin embargo al final del art\u00edculo, en la identificaci\u00f3n de posibles mejoras de SAVE se propone incluir el an\u00e1lisis din\u00e1mico, lo que se contradice con la afirmaci\u00f3n inicial. La descripci\u00f3n del funcionamiento de la herramienta no est\u00e1 lo suficientemente claro. La calidad de la figuras no es adecuada, por el tama\u00f1o y resoluci\u00f3n de las mismas no es posible apreciar bien los detalles. La redacci\u00f3n de art\u00edculo puede ser mejorada. Hay varias frases en donde faltan conectores, por ejemplo \"En el presente apartado, veremos S.A.V.E. logra recuperar las dependencias existentes en el c\u00f3digo fuente....\" Muchos errores en la acentuaci\u00f3n de las palabras.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "El trabajo presenta una encuesta a dos mineras sobre la etapa de arquitectura del proceso de outsourcing de TI. El trabajo es exploratorio y por lo tanto su contribuci\u00f3n es reducida ya que a\u00fan no se presentan resultados. Creo que en este estado es inadecuado para la conferencia donde se espera la presentaci\u00f3n de resultados y contribuciones a la investigaci\u00f3n. El documento debe ser mejorado en cuanto a su redacci\u00f3n.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This work proposes to compute embeddings of symbolic expressions (e.g., boolean expressions, or polynomials) such that semantically equivalent expressions are near each other in the embedded space.  The proposed model uses recursive neural networks where the architecture is made to match that of the parse tree of a given symbolic expression.  To train the model parameters, the authors create a dataset of expressions where semantic equivalence relationships are known and minimize a loss function so that equivalent expressions are closer to each other than non-equivalent expressions via a max-margin loss function.  The authors also use a \u201csubexpression forcing\u201d mechanism which, if I understand it correctly, encourages the embeddings to respect some kind of compositionality.  Results are shown on a few symbolic expression datasets created by the authors and the proposed method is demonstrated to outperform baselines pretty convincingly.  I especially like the PCA visualization where the action of negating an expression is shown to correspond roughly to negating the embedding in its vector space \u2014 it is a lot like the man - woman + queen = king type embeddings that we see in the word2vec and glove style papers.    The weakest part of the paper is probably that the setting seems somewhat contrived \u2014 I can\u2019t really think of a real setting where it is easy to have a training set of known semantic equivalences, but still more worth it to use a neural network to do predictions.   The authors have also punted on dealing with variable names, assuming that distinct variables refer to different entities in the domain.  This is understandable, as variable names add a whole new layer of complexity on an already difficult problem, but also seems high limiting.  For example, the proposed methods would not be useable in an \u201cequation search engine\u201d unless we were able to accurately canonicalize variable names in some way.  Other miscellaneous points: * Regarding problem hardness, I believe that the problem of determining if two expressions are equivalent is actually undecidable \u2014 see the \u201cword problem for Thue systems\u201d.  Related to this, I was not able to figure out how the authors determine ground truth equivalence in their training sets.  They say that expressions are simplified into a canonical form and grouped, but this seems to not be possible in general, so one question is \u2014 is it possible that equivalent expressions in the training data would have been mapped to different canonical forms?  Would it have been easier/possible to construct and compare truth tables? * The \u201cCOMBINE\u201d operation uses what the authors describe as a residual-like connection.  Looking at the equations, the reason why this is not actually a residual connection is because of the weight matrix that is multiplied by the lower level l_0 features.  A true residual connection would have passed the features through unchanged (identity connection) and would have also been better at fighting gradient explosion\u2026. so is there a reason why this was used rather than an identity connection? * In table 3, the first tf-idf entry: a + (c+a) * c seems equivalent to a + (c * (a+c)) * Vertical spacing between Figure 4 caption and body of text is very small and looks like the caption continues into the body of the text.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "This paper proposes a character-aware attention residual network for sentence embedding. Several text classification tasks are used to evaluate the effectiveness of the proposed model. On two of the three tasks, the residual network outforms a few baselines, but couldn't beat the simple TFIDF-SVM on the last one.  This work is not novel enough. Character information has been applied in many previously published work, as cited by the authors. Residual network is also not new.  Why not testing the model on a few more widely used datasets for short text classification, such as TREC? More competitive baselines can be compared to. Also, it's not clear how the \"Question\" dataset was created and which domain it is.  Last, it is surprising that the format of citations throughout the paper is all wrong.   For example: like Word2Vec Mikolov et al. (2013) -> like Word2Vec (Mikolov et al., 2013)  The citations can't just mix with the normal text. Please refer to other published papers.", "output": "en", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Este art\u00edculo describe los resultados de simulaci\u00f3n del problema de pliegue de prote\u00ednas en base a una secuencia de amino\u00e1cidos.  En general, el art\u00edculo presenta varios problemas de redacci\u00f3n y de ortograf\u00eda (e.g., segundo p\u00e1rrafo, lineas 4 y 8 del resumen). Tambi\u00e9n, usualmente se utilizan p\u00e1rrafos muy extensos que hacen dif\u00edcil seguir la idea de lo expuesto (e.g., segundo p\u00e1rrafo de introducci\u00f3n, secci\u00f3n redes neuronales artificiales).  Algunas figuras (e.g., 1, 3, 4,...) requieren mayor resoluci\u00f3n.  No obstante ser un problema bien explorado, la revisi\u00f3n del estado del arte y trabajos relacionados es limitada.  Los resultados se presentan mediante im\u00e1genes de la estructura molecular. Es conveniente presentar medidas de rendimiento y una descripci\u00f3n en notaci\u00f3n formal abstracta del algoritmo  utilizado.", "output": "es", "category": "Language Identification 893.json"}, {"instruction": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].", "input": "Ese trabajo muestra el procedimiento propuesto para la Identificaci\u00f3n autom\u00e1tica de fracturas en im\u00e1genes de pozos. La metodolog\u00eda se ve novedosa e interesante. El art\u00edculo muestra bien la metodolog\u00eda y tiene una buena redacci\u00f3n. Se agregaron m\u00e9tricas para medir la efectividad del algoritmo.  Este trabajo fue presentado en INFONOR 2014 y la redacci\u00f3n actual es la misma, que si bien es cierto es buena, presenta los mismos peque\u00f1os errores que en el art\u00edculo anterior. Por lo tanto, debe volver a revisarlo.  Aunque ahora muestra m\u00e9tricas para medir el resultado no se indica qu\u00e9 tan efectivo es este sistema respecto al utilizado antes.  Debe mejorar las figuras 12 y 15, en donde muestras las m\u00e9tricas. La figura 2, izquierda no se distingue. Falta incluir una referencia a la figura 11 en el texto.", "output": "es", "category": "Language Identification 893.json"}]