[{"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "YAW GOT MY BABYDADDY @YoungDolph FUCKED UP&#129315;&#128044;&#128044;&#128044;&#128044;&#128044; #Bulletproof", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"@Ferocious_Ghost: @1stName_Bravo Aw.\" ...fag, don't tweet \"aw\" to me lol", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @queenc_nt: &#8220;@_100d: 90% of niggas goofy and act like bitches&#8221; YOU AINT LYIN", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@Steven_ratata my boots get me bitches so", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @_TyMoore: For all those watching that so raven. Look at this negro now lol&#128514;&#128514;&#128553;&#128553; http://t.co/nEcAKyTdI1", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @itscoleharmon_: Birth Control should be mandatory for some of you hoes", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@miranda_mills okay, let's fight you ginger faggot", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Why does this faggot in front of me have to get two dozen doughnuts right now, get the fuck on", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "He could be right... any hoe they had in the 11wd, niggas from the hood RAN thru em....", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "The strike #antimarch should be violent and dangerous. South African government only understand violence much better than normal language", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @Marlin_FishyAss: Damn hoes askin niggas do I smoke.... No bitch u not getting smoked out tonight", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "The city used to have HOES.Now them bitches look sick.", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "These hoes ain't shit I ain't tripping off a Thot... ion like conversation you gone let me fuck or not", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "&#8220;@avelindner: if he has a girlfriend don't be a hoe and text him yanno who u r &#128519;&#8221;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "\"@Goofstroop: You a woulda coulda shoulda ass hoe &#128563;&#128586;\"", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Feminist aka a bitch.", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "All the hoes I did have now they decided they wanted to be wifey type draya fuck all that up", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "If yall niggas gon be gay, why yall gotta be so over the top? Dressing up in bitch shit that women wouldnt even dare wear. Smh.", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Mr #Trump will be loving today. As it is the one day of the year when #FakeNews is acceptable. #aprilfools", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "@SicilianInHeels @y3lla lol that's basically like the \"you got too many hoes\" curve", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "These hoes they loving the crewwww &#128564;", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Gay ass nigga &#128514;&#128514; bitch you thought you thought", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "when harmos talk about feminism no doubt that it makes me fucking cringe", "output": "No", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @Cluelessnigga: Fat hoes always wanna beef with somebody, yall don't need to be around no type of beef", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "to me niggas cheat on they bad bitches bc they think they can get more bad bitches, that one girl will give em a big ass ego", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "All the pictures of the ex are gone...there's no pictures with the side hoe posted...*slides into his dm's like* http://t.co/XMVtZ0GTPp", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "Jean skirt ass hoe", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "&#128064; RT @Freegeezy17: This hoe got a school shirt on sucking dick &#128553;&#128553;&#128553;&#128553;&#128553;&#128553;", "output": "Yes", "category": "Toxic Language Detection 1236.json"}, {"instruction": "In this task, you are given a text from a social media post. Your task is to classify the given post into two categories: 1) yes if the given post is potentially offensive to anyone (i.e., a subset of people, any particular person, etc.), 2) no, otherwise. Note that potentially offensive posts can contain sexual, racial, religious biased or offensive language. Warning: the examples and instances may contain offensive language.", "input": "RT @King_Lonnie_19: \"@TaeCocky: Rihanna is a talented hoe\" http://t.co/uL4ePHA2qy", "output": "Yes", "category": "Toxic Language Detection 1236.json"}]