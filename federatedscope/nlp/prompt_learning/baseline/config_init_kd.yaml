use_gpu: True
device: 7
seed: 12345
outdir: exp
federate:
  mode: standalone
  method: fedavg
  total_round_num: 1
  client_num: 20
  make_global_eval: True
  pl_alter_train: False
data:
  type: pl_data
  batch_size: 16
  max_seq_len: 128
  num_workers: 0
model:
  type: pl_model
  model_type: bert-large-cased
  num_server_layers: 24
  num_client_layers: 24
  server_prefix_len: 0
  client_prefix_len: 0
  server_freeze_param: ['model']
  only_use_hidden_loss: True
  share_client_layer_param: True
trainer:
  type: pl_trainer
train:
  batch_or_epoch: batch
  local_update_steps: 5000
  optimizer:
    type: AdamW
    lr: 5e-4
    weight_decay: 0.01
  scheduler:
    type: warmup_step
    warmup_ratio: 0.1
