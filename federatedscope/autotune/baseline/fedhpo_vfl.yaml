# How to use:
# python federatedscope/hpo.py --cfg \
#  federatedscope/autotune/baseline/fedhpo_vfl.yaml wandb.use \
#  True wandb.name_project vfl_demo wandb.name_user vfl_demo

use_gpu: False
device: 0
backend: torch
outdir: vFL_adult
federate:
  mode: standalone
  client_num: 2
  total_round_num: 30
model:
  type: xgb_tree
  lambda_: 0.1
  gamma: 0
  num_of_trees: 10
  max_tree_depth: 3
train:
  optimizer:
    lr: 0.5
    # learning rate for xgb model
    eta: 0.5
data:
  root: data/
  type: adult
  splits: [1.0, 0.0]
  args: [{normalization: False, standardization: True}]
feat_engr:
  scenario: vfl
dataloader:
  type: raw
  batch_size: 50
criterion:
  type: CrossEntropyLoss
trainer:
  type: verticaltrainer
vertical:
  use: True
  key_size: 256
  dims: [7, 14]
  algo: 'xgb'
eval:
  freq: 1
  best_res_update_round_wise_key: test_loss
hpo:
  scheduler: bo_rf
  num_workers: 0
  init_cand_num: 50
  ss: 'federatedscope/autotune/baseline/vfl_ss.yaml'
  sha:
    budgets: [ 50, 50 ]
    elim_rate: 3
    iter: 150
  metric: 'server_global_eval.test_acc'
  working_folder: rs
  # Enable wandb
  diagnosis:
    use: True
    landscape_1d: ['feat_engr.type', 'vertical.algo', 'vertical.dims', 'model.num_of_trees']
