use_gpu: True
device: 0
<<<<<<< HEAD
early_stopping: 100
=======
early_stop:
  patience: 100
  improve_indicator_mode: mean
>>>>>>> be synchronized with gitlab
federate:
  mode: standalone
  make_global_eval: True
  local_update_steps: 100
  total_round_num: 400
data:
  root: data/
  loader: graphsaint-rw
  batch_size: 256
  type: dblp_conf
model:
  type: sage
  hidden: 1024
  out_channels: 4
optimizer:
  lr: 0.05
  weight_decay: 0.0005
  type: SGD
criterion:
  type: CrossEntropyLoss
trainer:
  type: nodeminibatch_trainer
eval:
  metrics: ['acc', 'correct']
