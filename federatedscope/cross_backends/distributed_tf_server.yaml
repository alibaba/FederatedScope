use_gpu: False
backend: 'tensorflow'
federate:
  client_num: 3
  mode: 'distributed'
  total_round_num: 20
  make_global_eval: True
  online_aggr: False
distribute:
  use: True
  server_host: '127.0.0.1'
  server_port: 50051
  role: 'server'
trainer:
  type: 'general'
eval:
  freq: 10
data:
  type: 'file'
  file_path: 'toy_data/server_data'
model:
  type: 'lr'