use_gpu: True
device: 0
early_stop:
  patience: 100
federate:
  mode: standalone
  total_round_num: 500
  sample_client_rate: 0.01
  make_global_eval: True
  merge_test_data: True
  share_local_model: True
  online_aggr: True
data:
  root: data/
  type: twitter
  batch_size: 5
  subsample: 0.005
  num_workers: 0
model:
  type: lr
  out_channels: 2
  dropout: 0.0
train:
  local_update_steps: 10
  optimizer:
    lr: 0.0003
    weight_decay: 0.0
criterion:
  type: CrossEntropyLoss
trainer:
  type: nlptrainer
eval:
  freq: 1
  metrics: ['acc', 'correct', 'f1']
  split: [ 'test' ]
  best_res_update_round_wise_key: 'test_loss'